{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f23732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# import skorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from ptsa.data.timeseries import TimeSeries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate\n",
    "\n",
    "#### PYTORCH CONFIGURATION SETTINGS ######\n",
    "device = \"cpu\"\n",
    "#FOR GPU: device = \"mps\" if torch.has_mps else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9a127",
   "metadata": {},
   "source": [
    "### Logistic Regression PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df177839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "        \n",
    "class LogisticRegressionTorch(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.logistic = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, output_dim, bias=True),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # logits = torch.sigmoid(self.linear(x))\n",
    "        probs = self.logistic(x)\n",
    "        return probs\n",
    "    \n",
    "class PrecondLogisticRegressionTorch(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.condition = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=16, kernel_size=4, padding=1, groups=input_dim),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=16, kernel_size=3, padding=1, groups=input_dim),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=16, kernel_size=3, padding=1, groups=input_dim),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=16, kernel_size=3, padding=1, groups=input_dim),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "#             nn.Conv1d(in_channels=input_dim, out_channels=16, kernel_size=3, padding=1, groups=input_dim),\n",
    "#             nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        self.logistic = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_cond = self.condition(x)\n",
    "        probs = self.logistic(x)\n",
    "        return probs\n",
    "\n",
    "    \n",
    "def train_loop(dataloader, model, loss_fn, optimizer, print_nth_batch=4, l2=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(\"yay training\")\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # print(y)\n",
    "        # Compute prediction and loss\n",
    "        pred = torch.squeeze(model(X))\n",
    "        # print(pred)\n",
    "        # regularization, computing largest singular value\n",
    "        loss = loss_fn(pred, y)\n",
    "        # if l2:\n",
    "        #     loss = loss + l2*l2_reg(model)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % print_nth_batch == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # we don't want to track gradients here because we're just doing\n",
    "    # a forward pass to evaluate predictions\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = torch.squeeze(model(X))\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # round predicted probs to get label prediction, compute n correct\n",
    "            correct += (pred.round() == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "def test_auc_score(dataset, model):\n",
    "    with torch.no_grad():\n",
    "        X, y = dataset[:]\n",
    "        pred = model(X)\n",
    "        pred, y = pred.detach().numpy(), y.detach().numpy()\n",
    "        score = roc_auc_score(y_true=y, y_score=pred)\n",
    "        print(\"AUC:\", score)\n",
    "    return score\n",
    "\n",
    "def l2_reg(model):\n",
    "  \"\"\"\n",
    "  This function calculates the l2 norm of the all the tensors in the model\n",
    "  Args:\n",
    "    model: nn.module\n",
    "      Neural network instance\n",
    "  Returns:\n",
    "    l2: float\n",
    "      L2 norm of the all the tensors in the model\n",
    "  \"\"\"\n",
    "\n",
    "  l2 = 0.0\n",
    "  for param in model.parameters():\n",
    "    l2 += torch.sum(torch.abs(param)**2)\n",
    "\n",
    "  return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = torch.rand(1000, 128) #+ .2\n",
    "y_1 = torch.zeros(1000,)\n",
    "X_2 = torch.rand(1000, 128) #- .1\n",
    "y_2 = torch.ones(1000,)\n",
    "\n",
    "X = torch.cat((X_1, X_2))\n",
    "y = torch.cat((y_1, y_2))\n",
    "\n",
    "dataset = SimpleDataset(X, y)\n",
    "\n",
    "train_prop = .8\n",
    "train_num = int(train_prop * len(dataset))\n",
    "test_num = len(X) - train_num\n",
    "\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                    [train_num, test_num])\n",
    "\n",
    "\n",
    "target = train_set.dataset.y[train_set.indices]\n",
    "cls_weights = torch.from_numpy(\n",
    "    compute_class_weight(class_weight='balanced',\n",
    "                         classes=np.unique(target.numpy()),\n",
    "                         y=target.numpy())\n",
    ")\n",
    "weights = cls_weights[target.numpy()]\n",
    "sampler = WeightedRandomSampler(weights, len(target.numpy()), replacement=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=100, sampler=sampler)\n",
    "test_dataloader = DataLoader(test_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0b2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionTorch(128)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "weight_decay = 1\n",
    "lr = 5e-1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9d7c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 56 has been set.\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.700848  [    0/ 1600]\n",
      "loss: 3.608657  [  400/ 1600]\n",
      "loss: 2.541048  [  800/ 1600]\n",
      "loss: 3.054665  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 2.443158 \n",
      "\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.431442  [    0/ 1600]\n",
      "loss: 2.771903  [  400/ 1600]\n",
      "loss: 3.974485  [  800/ 1600]\n",
      "loss: 3.103239  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 2.955838 \n",
      "\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.563055  [    0/ 1600]\n",
      "loss: 2.165828  [  400/ 1600]\n",
      "loss: 2.362202  [  800/ 1600]\n",
      "loss: 4.232868  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 2.562103 \n",
      "\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.818193  [    0/ 1600]\n",
      "loss: 2.694793  [  400/ 1600]\n",
      "loss: 2.470912  [  800/ 1600]\n",
      "loss: 3.691533  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 3.166436 \n",
      "\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.485358  [    0/ 1600]\n",
      "loss: 2.304926  [  400/ 1600]\n",
      "loss: 2.594493  [  800/ 1600]\n",
      "loss: 2.629220  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 2.730952 \n",
      "\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.469204  [    0/ 1600]\n",
      "loss: 2.621750  [  400/ 1600]\n",
      "loss: 3.293433  [  800/ 1600]\n",
      "loss: 2.838146  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 2.580966 \n",
      "\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.662794  [    0/ 1600]\n",
      "loss: 2.723584  [  400/ 1600]\n",
      "loss: 3.329403  [  800/ 1600]\n",
      "loss: 2.481059  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.166831 \n",
      "\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.182785  [    0/ 1600]\n",
      "loss: 2.296135  [  400/ 1600]\n",
      "loss: 1.891554  [  800/ 1600]\n",
      "loss: 4.289261  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 3.087149 \n",
      "\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.700690  [    0/ 1600]\n",
      "loss: 3.229460  [  400/ 1600]\n",
      "loss: 3.076186  [  800/ 1600]\n",
      "loss: 3.574790  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 3.084764 \n",
      "\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.917437  [    0/ 1600]\n",
      "loss: 2.958801  [  400/ 1600]\n",
      "loss: 2.783141  [  800/ 1600]\n",
      "loss: 2.662864  [ 1200/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 2.703714 \n",
      "\n",
      "Done!\n",
      "CPU times: user 323 ms, sys: 11.7 ms, total: 335 ms\n",
      "Wall time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "set_seed(56)\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"{'-'*30}\\nEpoch {t+1}\\n{'-'*30}\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(train_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9180ab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.0873, 0.0627, 0.0893, 0.0677, 0.0944, 0.1175, 0.1002, 0.0882, 0.0907,\n",
       "          0.0787, 0.0842, 0.0790, 0.0744, 0.0822, 0.0884, 0.0700, 0.0678, 0.0974,\n",
       "          0.0767, 0.0932, 0.0832, 0.0784, 0.0782, 0.0734, 0.0815, 0.0730, 0.0838,\n",
       "          0.0893, 0.0743, 0.0683, 0.0827, 0.0797, 0.1005, 0.0763, 0.0731, 0.0935,\n",
       "          0.0985, 0.0928, 0.0562, 0.0774, 0.0985, 0.0951, 0.0668, 0.0929, 0.0797,\n",
       "          0.0988, 0.0913, 0.0982, 0.1249, 0.0841, 0.0811, 0.0687, 0.0641, 0.0764,\n",
       "          0.0814, 0.0916, 0.0688, 0.0698, 0.0840, 0.0582, 0.1002, 0.0767, 0.0970,\n",
       "          0.0733, 0.0931, 0.1025, 0.0664, 0.0462, 0.0751, 0.0708, 0.0863, 0.0707,\n",
       "          0.0872, 0.0753, 0.0955, 0.0802, 0.0595, 0.0785, 0.0980, 0.0666, 0.0853,\n",
       "          0.0780, 0.0771, 0.0829, 0.1118, 0.0974, 0.0849, 0.0660, 0.0730, 0.0833,\n",
       "          0.0701, 0.0702, 0.0955, 0.0938, 0.0811, 0.0885, 0.0848, 0.0828, 0.0817,\n",
       "          0.0879, 0.0655, 0.0761, 0.0785, 0.0909, 0.1033, 0.0626, 0.0782, 0.0864,\n",
       "          0.0843, 0.0766, 0.0892, 0.0767, 0.0753, 0.0728, 0.0828, 0.0872, 0.0716,\n",
       "          0.0747, 0.0815, 0.0867, 0.0748, 0.0686, 0.0993, 0.0938, 0.1050, 0.0878,\n",
       "          0.0928, 0.0780]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1657], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44523b9",
   "metadata": {},
   "source": [
    "## Compare to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298d8cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 517 ms, sys: 140 ms, total: 658 ms\n",
      "Wall time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sk_model = LogisticRegression(penalty='l2', C=1e-4, class_weight='balanced', fit_intercept=True, solver='saga')\n",
    "\n",
    "train_idx = train_set.indices\n",
    "test_idx = test_set.indices\n",
    "sk_train_X = train_set.dataset.X[train_idx].detach().numpy()\n",
    "sk_train_y = train_set.dataset.y[train_idx].detach().numpy()\n",
    "sk_test_X = test_set.dataset.X[test_idx].detach().numpy()\n",
    "sk_test_y = test_set.dataset.y[test_idx].detach().numpy()\n",
    "fit = sk_model.fit(sk_train_X, sk_train_y)\n",
    "\n",
    "sk_pred = fit.predict(sk_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36fbc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sk_test_y, sk_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a440f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.4131160e-04, -4.6132575e-04,  3.4445897e-04,  1.8519568e-04,\n",
       "        -5.4830051e-04,  1.1141150e-03, -6.4614945e-04, -1.1913801e-03,\n",
       "        -3.7327985e-04, -3.0545960e-04, -2.6876479e-04, -3.1180453e-04,\n",
       "         4.6721124e-04,  3.5252771e-04,  8.6313921e-05,  7.5289333e-04,\n",
       "        -7.7934272e-04,  9.0795686e-04, -2.3124235e-04,  2.1582688e-04,\n",
       "        -9.3807808e-05, -1.0474667e-04,  4.9194007e-04,  5.1707128e-04,\n",
       "        -1.9614457e-04,  7.8363984e-04, -2.8293953e-05,  7.8600424e-05,\n",
       "        -2.0287099e-04, -2.3677357e-04, -3.1233093e-04, -1.0019947e-03,\n",
       "        -4.0162457e-05,  5.6729501e-04,  3.0720248e-04, -4.3040048e-04,\n",
       "        -2.2268898e-04,  2.5102257e-04, -2.8418738e-04,  6.3262979e-04,\n",
       "        -2.7471068e-04,  2.0574310e-04,  3.1120345e-04,  1.2792593e-03,\n",
       "         5.6858611e-04,  2.4843967e-04,  5.3513999e-04,  9.0322195e-04,\n",
       "        -4.8988668e-04, -1.2738239e-03,  6.8290345e-04,  5.9528858e-04,\n",
       "        -4.0988976e-04,  8.5013092e-04,  3.0823151e-04,  2.0874029e-03,\n",
       "        -3.0617672e-04, -4.0824062e-04, -4.2903948e-06, -1.1783584e-04,\n",
       "         6.3670141e-04, -9.3467062e-04,  7.8367849e-04,  2.5200026e-04,\n",
       "         6.5873278e-04, -6.8158389e-04, -9.8663603e-04,  9.7350014e-05,\n",
       "         1.0902564e-03, -1.5022345e-03, -1.1456390e-03, -4.5551782e-04,\n",
       "         3.3069940e-04,  6.1732433e-05,  3.7100480e-04, -7.9039244e-05,\n",
       "        -8.5158693e-04,  2.6078173e-04,  3.7756731e-04,  2.9259725e-04,\n",
       "         9.4372645e-04, -1.3014600e-03,  2.5861638e-04,  4.2110975e-04,\n",
       "         1.9324782e-04, -6.5872871e-04,  2.7720808e-04, -7.7167060e-04,\n",
       "        -4.0394373e-04,  4.5212079e-04,  4.7982354e-05, -8.1399985e-04,\n",
       "         6.8026379e-04, -9.2464924e-04, -2.1416684e-04, -2.2713738e-04,\n",
       "         4.8547279e-04,  6.1370095e-04,  3.5370889e-05, -6.6408618e-05,\n",
       "        -1.3982686e-05,  5.1116559e-04, -1.9595087e-04, -2.0331201e-05,\n",
       "         8.9943042e-04, -1.2561561e-04, -3.6276385e-04, -4.8934465e-04,\n",
       "        -3.5416769e-04, -2.3823918e-04, -7.0193456e-04,  4.1693859e-04,\n",
       "        -4.9441785e-04, -3.9764913e-04,  4.3006570e-04, -1.3705835e-04,\n",
       "         4.9023045e-04,  7.2352916e-05,  1.9055592e-06,  3.8289357e-04,\n",
       "         8.5104152e-04, -2.7558210e-04,  4.4361220e-04, -8.3127881e-05,\n",
       "         3.1079736e-04,  4.6169807e-05,  3.8469447e-05,  1.0558804e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1f81f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00210631], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd598b6",
   "metadata": {},
   "source": [
    "## Using lab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672cd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeries.from_hdf(\n",
    "    \"/scratch/jrudoler/scalp_features/LTP093_feats.h5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "888e3e17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.TimeSeries &#x27;data&#x27; (event: 13248, frequency: 20, channel: 124)&gt;\n",
       "array([[[ 1.39587653e+00,  1.70742426e+00,  5.54105948e-01, ...,\n",
       "          9.26949346e-01,  3.60765826e-01, -4.20605905e-01],\n",
       "        [ 4.44943446e-01,  1.57553103e+00, -1.62710896e-01, ...,\n",
       "         -4.91543365e-01, -2.50837113e-01, -7.30371355e-01],\n",
       "        [-1.86757167e-01,  2.04167053e-02, -4.20472639e-01, ...,\n",
       "         -6.45690370e-01, -1.85106045e-01, -3.39612897e-01],\n",
       "        ...,\n",
       "        [-8.95425926e-01,  9.27001518e-01, -2.30120292e-01, ...,\n",
       "          5.17276271e-01, -9.61746937e-01, -2.34628751e-01],\n",
       "        [-8.27941491e-01,  7.75734020e-01, -2.41032913e-01, ...,\n",
       "         -4.35922181e-01, -1.03758902e+00, -5.21911629e-01],\n",
       "        [-9.90258257e-01,  8.86551266e-01, -5.43131051e-01, ...,\n",
       "         -9.71533419e-01, -1.26069151e+00, -6.74849604e-01]],\n",
       "\n",
       "       [[ 1.27620053e+00,  1.02151463e+00, -1.81685460e+00, ...,\n",
       "         -1.56056774e+00, -1.29049560e+00, -1.10462495e+00],\n",
       "        [ 1.91133981e+00, -2.95863846e-01, -7.25485833e-01, ...,\n",
       "         -2.64510390e+00, -1.35901883e+00, -1.63381166e+00],\n",
       "        [ 9.65586904e-01, -9.59395733e-01, -3.25459627e-01, ...,\n",
       "         -2.12805101e+00, -1.76594402e+00, -3.90817817e-01],\n",
       "...\n",
       "        [ 1.67538293e-01, -2.06169238e-01,  7.16212495e-01, ...,\n",
       "         -3.87131904e-01, -9.77682499e-02,  4.38739303e-01],\n",
       "        [ 2.48287200e-01, -8.55439342e-02,  7.79705614e-01, ...,\n",
       "         -3.52362688e-01,  1.05727347e-01,  4.35295684e-01],\n",
       "        [ 1.99468895e-01, -8.62287564e-02,  9.38160889e-01, ...,\n",
       "         -3.55865449e-01,  3.45736801e-01,  4.89451156e-01]],\n",
       "\n",
       "       [[-2.50150520e-01, -6.87843058e-02, -7.37521323e-02, ...,\n",
       "         -1.57742590e+00, -3.11012437e+00, -2.08849377e-01],\n",
       "        [-5.59610990e-01,  1.31475643e+00,  1.13463066e+00, ...,\n",
       "          4.75671981e-01, -4.30557120e-01,  5.81532752e-01],\n",
       "        [ 7.17756255e-01,  1.44361107e+00,  3.51273401e-01, ...,\n",
       "          1.03740257e+00, -2.88860295e-02, -7.96719201e-01],\n",
       "        ...,\n",
       "        [-1.19300851e-01,  6.08363101e-01,  9.03034158e-01, ...,\n",
       "         -2.84023610e-01, -6.70062590e-02,  7.20343371e-01],\n",
       "        [-5.60094173e-02,  2.65321397e-01,  6.43879182e-01, ...,\n",
       "         -3.29366288e-01,  4.47337017e-02,  2.73048754e-01],\n",
       "        [-2.03685595e-01,  2.30178227e-01,  8.03178039e-01, ...,\n",
       "         -6.23034482e-01,  7.64283630e-02,  2.58570232e-01]]])\n",
       "Coordinates: (12/28)\n",
       "  * frequency           (frequency) float64 2.0 2.534 3.212 ... 142.0 180.0\n",
       "  * channel             (channel) object &#x27;E1&#x27; &#x27;E10&#x27; &#x27;E100&#x27; ... &#x27;E97&#x27; &#x27;E98&#x27; &#x27;E99&#x27;\n",
       "    samplerate          float64 500.0\n",
       "  * event               (event) object MultiIndex\n",
       "  * begin_distractor    (event) int64 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0\n",
       "  * begin_math_correct  (event) int64 -999 -999 -999 -999 ... -999 -999 -999\n",
       "    ...                  ...\n",
       "  * rectime             (event) int64 -999 -999 -999 -999 ... -999 -999 -999\n",
       "  * serialpos           (event) int64 1 2 3 4 5 6 7 8 ... 18 19 20 21 22 23 24\n",
       "  * session             (event) int64 0 0 0 0 0 0 0 0 ... 23 23 23 23 23 23 23\n",
       "  * subject             (event) object &#x27;LTP093&#x27; &#x27;LTP093&#x27; ... &#x27;LTP093&#x27; &#x27;LTP093&#x27;\n",
       "  * trial               (event) int64 1 1 1 1 1 1 1 1 ... 24 24 24 24 24 24 24\n",
       "  * type                (event) object &#x27;WORD&#x27; &#x27;WORD&#x27; &#x27;WORD&#x27; ... &#x27;WORD&#x27; &#x27;WORD&#x27;\n",
       "Attributes:\n",
       "    rel_start:    200\n",
       "    rel_stop:     1600\n",
       "    buffer_time:  1000\n",
       "    freqs:        [  2.           2.53445663   3.21173521   4.07000181   5.15...\n",
       "    width:        4\n",
       "    experiment:   ltpFR2\n",
       "    clean:        1\n",
       "    save:         1\n",
       "    reference:    average\n",
       "    cap_type:     EGI</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.TimeSeries</div><div class='xr-array-name'>'data'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>event</span>: 13248</li><li><span class='xr-has-index'>frequency</span>: 20</li><li><span class='xr-has-index'>channel</span>: 124</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-dc1d7b03-3a37-4831-bebe-ee3b43338bc6' class='xr-array-in' type='checkbox' checked><label for='section-dc1d7b03-3a37-4831-bebe-ee3b43338bc6' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1.396 1.707 0.5541 0.2455 0.951 ... -0.4219 -0.623 0.07643 0.2586</span></div><div class='xr-array-data'><pre>array([[[ 1.39587653e+00,  1.70742426e+00,  5.54105948e-01, ...,\n",
       "          9.26949346e-01,  3.60765826e-01, -4.20605905e-01],\n",
       "        [ 4.44943446e-01,  1.57553103e+00, -1.62710896e-01, ...,\n",
       "         -4.91543365e-01, -2.50837113e-01, -7.30371355e-01],\n",
       "        [-1.86757167e-01,  2.04167053e-02, -4.20472639e-01, ...,\n",
       "         -6.45690370e-01, -1.85106045e-01, -3.39612897e-01],\n",
       "        ...,\n",
       "        [-8.95425926e-01,  9.27001518e-01, -2.30120292e-01, ...,\n",
       "          5.17276271e-01, -9.61746937e-01, -2.34628751e-01],\n",
       "        [-8.27941491e-01,  7.75734020e-01, -2.41032913e-01, ...,\n",
       "         -4.35922181e-01, -1.03758902e+00, -5.21911629e-01],\n",
       "        [-9.90258257e-01,  8.86551266e-01, -5.43131051e-01, ...,\n",
       "         -9.71533419e-01, -1.26069151e+00, -6.74849604e-01]],\n",
       "\n",
       "       [[ 1.27620053e+00,  1.02151463e+00, -1.81685460e+00, ...,\n",
       "         -1.56056774e+00, -1.29049560e+00, -1.10462495e+00],\n",
       "        [ 1.91133981e+00, -2.95863846e-01, -7.25485833e-01, ...,\n",
       "         -2.64510390e+00, -1.35901883e+00, -1.63381166e+00],\n",
       "        [ 9.65586904e-01, -9.59395733e-01, -3.25459627e-01, ...,\n",
       "         -2.12805101e+00, -1.76594402e+00, -3.90817817e-01],\n",
       "...\n",
       "        [ 1.67538293e-01, -2.06169238e-01,  7.16212495e-01, ...,\n",
       "         -3.87131904e-01, -9.77682499e-02,  4.38739303e-01],\n",
       "        [ 2.48287200e-01, -8.55439342e-02,  7.79705614e-01, ...,\n",
       "         -3.52362688e-01,  1.05727347e-01,  4.35295684e-01],\n",
       "        [ 1.99468895e-01, -8.62287564e-02,  9.38160889e-01, ...,\n",
       "         -3.55865449e-01,  3.45736801e-01,  4.89451156e-01]],\n",
       "\n",
       "       [[-2.50150520e-01, -6.87843058e-02, -7.37521323e-02, ...,\n",
       "         -1.57742590e+00, -3.11012437e+00, -2.08849377e-01],\n",
       "        [-5.59610990e-01,  1.31475643e+00,  1.13463066e+00, ...,\n",
       "          4.75671981e-01, -4.30557120e-01,  5.81532752e-01],\n",
       "        [ 7.17756255e-01,  1.44361107e+00,  3.51273401e-01, ...,\n",
       "          1.03740257e+00, -2.88860295e-02, -7.96719201e-01],\n",
       "        ...,\n",
       "        [-1.19300851e-01,  6.08363101e-01,  9.03034158e-01, ...,\n",
       "         -2.84023610e-01, -6.70062590e-02,  7.20343371e-01],\n",
       "        [-5.60094173e-02,  2.65321397e-01,  6.43879182e-01, ...,\n",
       "         -3.29366288e-01,  4.47337017e-02,  2.73048754e-01],\n",
       "        [-2.03685595e-01,  2.30178227e-01,  8.03178039e-01, ...,\n",
       "         -6.23034482e-01,  7.64283630e-02,  2.58570232e-01]]])</pre></div></div></li><li class='xr-section-item'><input id='section-bf67a719-4daa-42f5-867a-abcd5bb3a6e3' class='xr-section-summary-in' type='checkbox'  ><label for='section-bf67a719-4daa-42f5-867a-abcd5bb3a6e3' class='xr-section-summary' >Coordinates: <span>(28)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>frequency</span></div><div class='xr-var-dims'>(frequency)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>2.0 2.534 3.212 ... 142.0 180.0</div><input id='attrs-f4c29768-35ad-44f9-8c66-396a672922c0' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f4c29768-35ad-44f9-8c66-396a672922c0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b3f98e16-2152-4576-88d1-029b68e5489b' class='xr-var-data-in' type='checkbox'><label for='data-b3f98e16-2152-4576-88d1-029b68e5489b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  2.      ,   2.534457,   3.211735,   4.070002,   5.157622,   6.535884,\n",
       "         8.282457,  10.495765,  13.30053 ,  16.854808,  21.35889 ,  27.066591,\n",
       "        34.29955 ,  43.465361,  55.080536,  69.799615,  88.452049, 112.088941,\n",
       "       142.04228 , 180.      ])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>channel</span></div><div class='xr-var-dims'>(channel)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;E1&#x27; &#x27;E10&#x27; &#x27;E100&#x27; ... &#x27;E98&#x27; &#x27;E99&#x27;</div><input id='attrs-09a3b2b6-d3d2-4798-9319-d7e65dbc61d4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-09a3b2b6-d3d2-4798-9319-d7e65dbc61d4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-577144c4-d5c1-442b-9f14-99ac7fc5b47d' class='xr-var-data-in' type='checkbox'><label for='data-577144c4-d5c1-442b-9f14-99ac7fc5b47d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;E1&#x27;, &#x27;E10&#x27;, &#x27;E100&#x27;, &#x27;E101&#x27;, &#x27;E102&#x27;, &#x27;E103&#x27;, &#x27;E104&#x27;, &#x27;E105&#x27;, &#x27;E106&#x27;,\n",
       "       &#x27;E107&#x27;, &#x27;E108&#x27;, &#x27;E109&#x27;, &#x27;E11&#x27;, &#x27;E110&#x27;, &#x27;E111&#x27;, &#x27;E112&#x27;, &#x27;E113&#x27;, &#x27;E114&#x27;,\n",
       "       &#x27;E115&#x27;, &#x27;E116&#x27;, &#x27;E117&#x27;, &#x27;E118&#x27;, &#x27;E119&#x27;, &#x27;E12&#x27;, &#x27;E120&#x27;, &#x27;E121&#x27;, &#x27;E122&#x27;,\n",
       "       &#x27;E123&#x27;, &#x27;E124&#x27;, &#x27;E125&#x27;, &#x27;E128&#x27;, &#x27;E13&#x27;, &#x27;E14&#x27;, &#x27;E15&#x27;, &#x27;E16&#x27;, &#x27;E17&#x27;,\n",
       "       &#x27;E18&#x27;, &#x27;E19&#x27;, &#x27;E2&#x27;, &#x27;E20&#x27;, &#x27;E21&#x27;, &#x27;E22&#x27;, &#x27;E23&#x27;, &#x27;E24&#x27;, &#x27;E26&#x27;, &#x27;E27&#x27;,\n",
       "       &#x27;E28&#x27;, &#x27;E29&#x27;, &#x27;E3&#x27;, &#x27;E30&#x27;, &#x27;E31&#x27;, &#x27;E32&#x27;, &#x27;E33&#x27;, &#x27;E34&#x27;, &#x27;E35&#x27;, &#x27;E36&#x27;,\n",
       "       &#x27;E37&#x27;, &#x27;E38&#x27;, &#x27;E39&#x27;, &#x27;E4&#x27;, &#x27;E40&#x27;, &#x27;E41&#x27;, &#x27;E42&#x27;, &#x27;E43&#x27;, &#x27;E44&#x27;, &#x27;E45&#x27;,\n",
       "       &#x27;E46&#x27;, &#x27;E47&#x27;, &#x27;E48&#x27;, &#x27;E49&#x27;, &#x27;E5&#x27;, &#x27;E50&#x27;, &#x27;E51&#x27;, &#x27;E52&#x27;, &#x27;E53&#x27;, &#x27;E54&#x27;,\n",
       "       &#x27;E55&#x27;, &#x27;E56&#x27;, &#x27;E57&#x27;, &#x27;E58&#x27;, &#x27;E59&#x27;, &#x27;E6&#x27;, &#x27;E60&#x27;, &#x27;E61&#x27;, &#x27;E62&#x27;, &#x27;E63&#x27;,\n",
       "       &#x27;E64&#x27;, &#x27;E65&#x27;, &#x27;E66&#x27;, &#x27;E67&#x27;, &#x27;E68&#x27;, &#x27;E69&#x27;, &#x27;E7&#x27;, &#x27;E70&#x27;, &#x27;E71&#x27;, &#x27;E72&#x27;,\n",
       "       &#x27;E73&#x27;, &#x27;E74&#x27;, &#x27;E75&#x27;, &#x27;E76&#x27;, &#x27;E77&#x27;, &#x27;E78&#x27;, &#x27;E79&#x27;, &#x27;E80&#x27;, &#x27;E81&#x27;, &#x27;E82&#x27;,\n",
       "       &#x27;E83&#x27;, &#x27;E84&#x27;, &#x27;E85&#x27;, &#x27;E86&#x27;, &#x27;E87&#x27;, &#x27;E88&#x27;, &#x27;E89&#x27;, &#x27;E9&#x27;, &#x27;E90&#x27;, &#x27;E91&#x27;,\n",
       "       &#x27;E92&#x27;, &#x27;E93&#x27;, &#x27;E94&#x27;, &#x27;E95&#x27;, &#x27;E96&#x27;, &#x27;E97&#x27;, &#x27;E98&#x27;, &#x27;E99&#x27;], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>samplerate</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>500.0</div><input id='attrs-485494d7-7018-4dd4-a3ed-389ba844e0e4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-485494d7-7018-4dd4-a3ed-389ba844e0e4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2112993c-fc38-4b27-8dd3-2151b938bfa3' class='xr-var-data-in' type='checkbox'><label for='data-2112993c-fc38-4b27-8dd3-2151b938bfa3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(500.)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>event</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>MultiIndex</div><input id='attrs-109d5f27-2891-4a59-911e-1b4dc641310b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-109d5f27-2891-4a59-911e-1b4dc641310b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-acd0d4b7-e90b-425a-a8f8-67083a75db65' class='xr-var-data-in' type='checkbox'><label for='data-acd0d4b7-e90b-425a-a8f8-67083a75db65' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([(0, -999, &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/0/ephys/current_processed/LTP093 20140902 0959.2.raw&#x27;, 285929, 1, &#x27;ltpFR2&#x27;, 24000, 10, 0, -999, &#x27;BALLOON&#x27;, 75, 0, 1, 1409671137192, &#x27;&#x27;, &#x27;ltp&#x27;, 1, -999, 1, 0, &#x27;LTP093&#x27;, 1, &#x27;WORD&#x27;),\n",
       "       (0, -999, &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/0/ephys/current_processed/LTP093 20140902 0959.2.raw&#x27;, 287177, 0, &#x27;ltpFR2&#x27;, 24000, 10, 0, -999, &#x27;MAILBOX&#x27;, 857, 0, 1, 1409671139687, &#x27;&#x27;, &#x27;ltp&#x27;, 1, -999, 2, 0, &#x27;LTP093&#x27;, 1, &#x27;WORD&#x27;),\n",
       "       (0, -999, &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/0/ephys/current_processed/LTP093 20140902 0959.2.raw&#x27;, 288442, 0, &#x27;ltpFR2&#x27;, 24000, 10, 0, -999, &#x27;FLOWER&#x27;, 584, 0, 1, 1409671142218, &#x27;&#x27;, &#x27;ltp&#x27;, 1, -999, 3, 0, &#x27;LTP093&#x27;, 1, &#x27;WORD&#x27;),\n",
       "       ...,\n",
       "       (0, -999, &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/23/ephys/current_processed/LTP093 20141202 0858.2.raw&#x27;, 2686640, 0, &#x27;ltpFR2&#x27;, 24000, 12, 0, -999, &#x27;HARP&#x27;, 689, 0, 1, 1417538699425, &#x27;&#x27;, &#x27;ltp&#x27;, 1, -999, 22, 23, &#x27;LTP093&#x27;, 24, &#x27;WORD&#x27;),\n",
       "       (0, -999, &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/23/ephys/current_processed/LTP093 20141202 0858.2.raw&#x27;, 2688001, 0, &#x27;ltpFR2&#x27;, 24000, 12, 0, -999, &#x27;DANCER&#x27;, 437, 0, 1, 1417538702146, &#x27;&#x27;, &#x27;ltp&#x27;, 1, -999, 23, 23, &#x27;LTP093&#x27;, 24, &#x27;WORD&#x27;),\n",
       "       (0, -999, &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/23/ephys/current_processed/LTP093 20141202 0858.2.raw&#x27;, 2689376, 0, &#x27;ltpFR2&#x27;, 24000, 12, 0, -999, &#x27;CANVAS&#x27;, 234, 0, 1, 1417538704896, &#x27;&#x27;, &#x27;ltp&#x27;, 1, -999, 24, 23, &#x27;LTP093&#x27;, 24, &#x27;WORD&#x27;)],\n",
       "      dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>begin_distractor</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0</div><input id='attrs-322e1e53-bc82-446a-993e-9aa7975e56f3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-322e1e53-bc82-446a-993e-9aa7975e56f3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1fb864fa-b51c-4724-b383-01ad236cfd9f' class='xr-var-data-in' type='checkbox'><label for='data-1fb864fa-b51c-4724-b383-01ad236cfd9f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 0, 0, ..., 0, 0, 0])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>begin_math_correct</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>-999 -999 -999 ... -999 -999 -999</div><input id='attrs-29e6383f-2640-4bb3-a689-584ccaf86af3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-29e6383f-2640-4bb3-a689-584ccaf86af3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d0e0840a-36cc-44b4-b7d4-8ddb2bf6b9cb' class='xr-var-data-in' type='checkbox'><label for='data-d0e0840a-36cc-44b4-b7d4-8ddb2bf6b9cb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-999, -999, -999, ..., -999, -999, -999])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>eegfile</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;/protocols/ltp/subjects/LTP093/...</div><input id='attrs-110f150e-ce10-464b-bb2f-21380f8aa801' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-110f150e-ce10-464b-bb2f-21380f8aa801' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ce69661e-12c5-42a5-92bc-f3657e8ce704' class='xr-var-data-in' type='checkbox'><label for='data-ce69661e-12c5-42a5-92bc-f3657e8ce704' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/0/ephys/current_processed/LTP093 20140902 0959.2.raw&#x27;,\n",
       "       &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/0/ephys/current_processed/LTP093 20140902 0959.2.raw&#x27;,\n",
       "       &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/0/ephys/current_processed/LTP093 20140902 0959.2.raw&#x27;,\n",
       "       ...,\n",
       "       &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/23/ephys/current_processed/LTP093 20141202 0858.2.raw&#x27;,\n",
       "       &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/23/ephys/current_processed/LTP093 20141202 0858.2.raw&#x27;,\n",
       "       &#x27;/protocols/ltp/subjects/LTP093/experiments/ltpFR2/sessions/23/ephys/current_processed/LTP093 20141202 0858.2.raw&#x27;],\n",
       "      dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>eegoffset</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>285929 287177 ... 2688001 2689376</div><input id='attrs-4f3fc131-3850-4cae-b49f-5735251042fb' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-4f3fc131-3850-4cae-b49f-5735251042fb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-234217e8-1b05-497e-a859-97776298ace4' class='xr-var-data-in' type='checkbox'><label for='data-234217e8-1b05-497e-a859-97776298ace4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 285929,  287177,  288442, ..., 2686640, 2688001, 2689376])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>eogArtifact</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1 0 0 3 0 0 0 0 ... 0 0 0 0 3 0 0 0</div><input id='attrs-3aa2ec4b-ede2-4953-8ac2-522cb9ec29c1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3aa2ec4b-ede2-4953-8ac2-522cb9ec29c1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2823847e-dae9-4028-b67f-42bced3096e6' class='xr-var-data-in' type='checkbox'><label for='data-2823847e-dae9-4028-b67f-42bced3096e6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1, 0, 0, ..., 0, 0, 0])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>experiment</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;ltpFR2&#x27; &#x27;ltpFR2&#x27; ... &#x27;ltpFR2&#x27;</div><input id='attrs-34e6f7d0-3ea3-4f27-aae0-194978a836ee' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-34e6f7d0-3ea3-4f27-aae0-194978a836ee' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ed81dc02-ba42-4bf1-a023-84f7ac55b04c' class='xr-var-data-in' type='checkbox'><label for='data-ed81dc02-ba42-4bf1-a023-84f7ac55b04c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;ltpFR2&#x27;, &#x27;ltpFR2&#x27;, &#x27;ltpFR2&#x27;, ..., &#x27;ltpFR2&#x27;, &#x27;ltpFR2&#x27;, &#x27;ltpFR2&#x27;],\n",
       "      dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>final_distractor</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>24000 24000 24000 ... 24000 24000</div><input id='attrs-891c9f42-5dff-491d-aef0-9b8d401a384e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-891c9f42-5dff-491d-aef0-9b8d401a384e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b68fcf1b-3e51-4666-b9f3-12f4eac08505' class='xr-var-data-in' type='checkbox'><label for='data-b68fcf1b-3e51-4666-b9f3-12f4eac08505' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([24000, 24000, 24000, ..., 24000, 24000, 24000])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>final_math_correct</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>10 10 10 10 10 ... 12 12 12 12 12</div><input id='attrs-26dc90a4-7b75-4b73-95f7-173d207abbe7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-26dc90a4-7b75-4b73-95f7-173d207abbe7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5cd2b89d-2b93-4a6b-a260-d9040d13fd8b' class='xr-var-data-in' type='checkbox'><label for='data-5cd2b89d-2b93-4a6b-a260-d9040d13fd8b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([10, 10, 10, ..., 12, 12, 12])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>intruded</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0</div><input id='attrs-2964b212-3f2d-4acc-b6c3-ee772c10f812' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2964b212-3f2d-4acc-b6c3-ee772c10f812' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0d9d65f6-48a1-4763-b8cf-89a9054916fa' class='xr-var-data-in' type='checkbox'><label for='data-0d9d65f6-48a1-4763-b8cf-89a9054916fa' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 0, 0, ..., 0, 0, 0])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>intrusion</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>-999 -999 -999 ... -999 -999 -999</div><input id='attrs-a5f7551d-0930-43fc-aea6-ea177d879eda' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a5f7551d-0930-43fc-aea6-ea177d879eda' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2d9fc16d-b085-49c2-9077-dc912c4df20f' class='xr-var-data-in' type='checkbox'><label for='data-2d9fc16d-b085-49c2-9077-dc912c4df20f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-999, -999, -999, ..., -999, -999, -999])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>item_name</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;BALLOON&#x27; &#x27;MAILBOX&#x27; ... &#x27;CANVAS&#x27;</div><input id='attrs-15783402-21fb-4527-b73d-f5b813377773' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-15783402-21fb-4527-b73d-f5b813377773' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-95c61a74-dd76-481d-8a1e-3fc8c0b01887' class='xr-var-data-in' type='checkbox'><label for='data-95c61a74-dd76-481d-8a1e-3fc8c0b01887' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;BALLOON&#x27;, &#x27;MAILBOX&#x27;, &#x27;FLOWER&#x27;, ..., &#x27;HARP&#x27;, &#x27;DANCER&#x27;, &#x27;CANVAS&#x27;],\n",
       "      dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>item_num</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>75 857 584 442 ... 1362 689 437 234</div><input id='attrs-ebe992e6-453b-46b7-9953-3b3d66f564e3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ebe992e6-453b-46b7-9953-3b3d66f564e3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9ebe038f-425f-4f64-b4f4-d6f7181430b0' class='xr-var-data-in' type='checkbox'><label for='data-9ebe038f-425f-4f64-b4f4-d6f7181430b0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 75, 857, 584, ..., 689, 437, 234])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>montage</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0</div><input id='attrs-de794ace-569a-419f-98da-941203506151' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-de794ace-569a-419f-98da-941203506151' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3ddf73ae-98da-4373-8d03-9524539d3f24' class='xr-var-data-in' type='checkbox'><label for='data-3ddf73ae-98da-4373-8d03-9524539d3f24' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0, 0, 0, ..., 0, 0, 0])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>msoffset</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1</div><input id='attrs-aa22a1c3-14d4-4bd6-b470-8a9122a993b3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-aa22a1c3-14d4-4bd6-b470-8a9122a993b3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7129d57c-60cb-41f6-bf5e-d04ef1f6e78b' class='xr-var-data-in' type='checkbox'><label for='data-7129d57c-60cb-41f6-bf5e-d04ef1f6e78b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1, 1, 1, ..., 1, 1, 1])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>mstime</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1409671137192 ... 1417538704896</div><input id='attrs-b6224734-ad30-4ef8-becc-955342b87b17' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b6224734-ad30-4ef8-becc-955342b87b17' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-035d5967-7255-49ae-bbb9-ce1b8ddd0d85' class='xr-var-data-in' type='checkbox'><label for='data-035d5967-7255-49ae-bbb9-ce1b8ddd0d85' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1409671137192, 1409671139687, 1409671142218, ..., 1417538699425,\n",
       "       1417538702146, 1417538704896])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>phase</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; ... &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27; &#x27;&#x27;</div><input id='attrs-eb7fbd3f-f890-4082-af95-a14eee71e35a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-eb7fbd3f-f890-4082-af95-a14eee71e35a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-75363a03-94a6-44e3-8771-40ce3514d3cd' class='xr-var-data-in' type='checkbox'><label for='data-75363a03-94a6-44e3-8771-40ce3514d3cd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, ..., &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>protocol</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;ltp&#x27; &#x27;ltp&#x27; &#x27;ltp&#x27; ... &#x27;ltp&#x27; &#x27;ltp&#x27;</div><input id='attrs-178715ba-f92f-4a46-9538-826132b10387' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-178715ba-f92f-4a46-9538-826132b10387' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7b8a6055-dd61-4db4-9199-2a565ab555fc' class='xr-var-data-in' type='checkbox'><label for='data-7b8a6055-dd61-4db4-9199-2a565ab555fc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;ltp&#x27;, &#x27;ltp&#x27;, &#x27;ltp&#x27;, ..., &#x27;ltp&#x27;, &#x27;ltp&#x27;, &#x27;ltp&#x27;], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>recalled</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1 1 1 1 1 1 1 0 ... 0 0 1 1 1 1 1 1</div><input id='attrs-448899ad-df01-49bd-be84-80e33ca9f4c1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-448899ad-df01-49bd-be84-80e33ca9f4c1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-827ee527-4532-4a96-b154-52f984e91aeb' class='xr-var-data-in' type='checkbox'><label for='data-827ee527-4532-4a96-b154-52f984e91aeb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1, 1, 1, ..., 1, 1, 1])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>rectime</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>-999 -999 -999 ... -999 -999 -999</div><input id='attrs-61243946-8bbb-4fa5-bbe8-883bfa83bbe4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-61243946-8bbb-4fa5-bbe8-883bfa83bbe4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-73754334-7f13-4503-b0cd-530192b21c17' class='xr-var-data-in' type='checkbox'><label for='data-73754334-7f13-4503-b0cd-530192b21c17' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-999, -999, -999, ..., -999, -999, -999])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>serialpos</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1 2 3 4 5 6 7 ... 19 20 21 22 23 24</div><input id='attrs-bdf506b4-561f-4608-aa87-b6b6571dccf7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-bdf506b4-561f-4608-aa87-b6b6571dccf7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4d9cd708-cc27-490e-952c-1e06fb373de5' class='xr-var-data-in' type='checkbox'><label for='data-4d9cd708-cc27-490e-952c-1e06fb373de5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 1,  2,  3, ..., 22, 23, 24])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>session</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 0 0 0 0 0 0 ... 23 23 23 23 23 23</div><input id='attrs-736526bc-f67b-45d1-a959-ba4ed8571a07' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-736526bc-f67b-45d1-a959-ba4ed8571a07' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-acd2f6de-693d-4558-9cd4-d630e4ca74aa' class='xr-var-data-in' type='checkbox'><label for='data-acd2f6de-693d-4558-9cd4-d630e4ca74aa' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 0,  0,  0, ..., 23, 23, 23])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>subject</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;LTP093&#x27; &#x27;LTP093&#x27; ... &#x27;LTP093&#x27;</div><input id='attrs-b63e8204-d259-4e49-9be0-178f20ac6e2a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b63e8204-d259-4e49-9be0-178f20ac6e2a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7f663d83-f41e-457d-b7df-0fc3a47442cd' class='xr-var-data-in' type='checkbox'><label for='data-7f663d83-f41e-457d-b7df-0fc3a47442cd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;LTP093&#x27;, &#x27;LTP093&#x27;, &#x27;LTP093&#x27;, ..., &#x27;LTP093&#x27;, &#x27;LTP093&#x27;, &#x27;LTP093&#x27;],\n",
       "      dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>trial</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1 1 1 1 1 1 1 ... 24 24 24 24 24 24</div><input id='attrs-2dcdc52b-072c-4beb-baf6-33961c562e57' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2dcdc52b-072c-4beb-baf6-33961c562e57' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-52c0a3f4-b7b1-4e88-abcc-9d9a5d701177' class='xr-var-data-in' type='checkbox'><label for='data-52c0a3f4-b7b1-4e88-abcc-9d9a5d701177' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 1,  1,  1, ..., 24, 24, 24])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>type</span></div><div class='xr-var-dims'>(event)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;WORD&#x27; &#x27;WORD&#x27; ... &#x27;WORD&#x27; &#x27;WORD&#x27;</div><input id='attrs-cf2e964c-cd42-4d4c-81aa-712d638c820c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-cf2e964c-cd42-4d4c-81aa-712d638c820c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d9978af6-69d6-40ce-b9cb-e1152ccde998' class='xr-var-data-in' type='checkbox'><label for='data-d9978af6-69d6-40ce-b9cb-e1152ccde998' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;WORD&#x27;, &#x27;WORD&#x27;, &#x27;WORD&#x27;, ..., &#x27;WORD&#x27;, &#x27;WORD&#x27;, &#x27;WORD&#x27;], dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-4a17a7ad-ad7f-4212-a0fe-efe876fb8236' class='xr-section-summary-in' type='checkbox'  ><label for='section-4a17a7ad-ad7f-4212-a0fe-efe876fb8236' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>event<br>begin_distractor<br>begin_math_correct<br>eegfile<br>eegoffset<br>eogArtifact<br>experiment<br>final_distractor<br>final_math_correct<br>intruded<br>intrusion<br>item_name<br>item_num<br>montage<br>msoffset<br>mstime<br>phase<br>protocol<br>recalled<br>rectime<br>serialpos<br>session<br>subject<br>trial<br>type</div></div><div class='xr-index-preview'>PandasMultiIndex</div><div></div><input id='index-eea6e7b9-6107-4618-909f-fe449e6ba489' class='xr-index-data-in' type='checkbox'/><label for='index-eea6e7b9-6107-4618-909f-fe449e6ba489' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(MultiIndex([(0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            ...\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...),\n",
       "            (0, -999, ...)],\n",
       "           name=&#x27;event&#x27;, length=13248))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>frequency</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-83b78dd5-d25e-4a25-86dc-7c9cbbeaf8d8' class='xr-index-data-in' type='checkbox'/><label for='index-83b78dd5-d25e-4a25-86dc-7c9cbbeaf8d8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([               2.0, 2.5344566339146937, 3.2117352145970997,\n",
       "              4.0700018105065245,  5.157621544341538,   6.53588406913888,\n",
       "               8.282457368763199, 10.495764511688764, 13.300529997328002,\n",
       "              16.854808243154668, 21.358890282611707, 27.066590584910667,\n",
       "                34.2995500326899, 43.465361060319935,  55.08053634241263,\n",
       "               69.79961536630354,    88.452049104911, 112.08894131864497,\n",
       "              142.04228045675728, 179.99999999999997],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;frequency&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>channel</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-61ebb88e-dfe3-4838-b977-4400be18a85e' class='xr-index-data-in' type='checkbox'/><label for='index-61ebb88e-dfe3-4838-b977-4400be18a85e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;E1&#x27;, &#x27;E10&#x27;, &#x27;E100&#x27;, &#x27;E101&#x27;, &#x27;E102&#x27;, &#x27;E103&#x27;, &#x27;E104&#x27;, &#x27;E105&#x27;, &#x27;E106&#x27;,\n",
       "       &#x27;E107&#x27;,\n",
       "       ...\n",
       "       &#x27;E90&#x27;, &#x27;E91&#x27;, &#x27;E92&#x27;, &#x27;E93&#x27;, &#x27;E94&#x27;, &#x27;E95&#x27;, &#x27;E96&#x27;, &#x27;E97&#x27;, &#x27;E98&#x27;, &#x27;E99&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;channel&#x27;, length=124))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-26ad3b8a-abf9-4ab4-bb9c-7ea2a8e0a2cb' class='xr-section-summary-in' type='checkbox'  ><label for='section-26ad3b8a-abf9-4ab4-bb9c-7ea2a8e0a2cb' class='xr-section-summary' >Attributes: <span>(10)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>rel_start :</span></dt><dd>200</dd><dt><span>rel_stop :</span></dt><dd>1600</dd><dt><span>buffer_time :</span></dt><dd>1000</dd><dt><span>freqs :</span></dt><dd>[  2.           2.53445663   3.21173521   4.07000181   5.15762154\n",
       "   6.53588407   8.28245737  10.49576451  13.30053     16.85480824\n",
       "  21.35889028  27.06659058  34.29955003  43.46536106  55.08053634\n",
       "  69.79961537  88.4520491  112.08894132 142.04228046 180.        ]</dd><dt><span>width :</span></dt><dd>4</dd><dt><span>experiment :</span></dt><dd>ltpFR2</dd><dt><span>clean :</span></dt><dd>1</dd><dt><span>save :</span></dt><dd>1</dd><dt><span>reference :</span></dt><dd>average</dd><dt><span>cap_type :</span></dt><dd>EGI</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.TimeSeries 'data' (event: 13248, frequency: 20, channel: 124)>\n",
       "array([[[ 1.39587653e+00,  1.70742426e+00,  5.54105948e-01, ...,\n",
       "          9.26949346e-01,  3.60765826e-01, -4.20605905e-01],\n",
       "        [ 4.44943446e-01,  1.57553103e+00, -1.62710896e-01, ...,\n",
       "         -4.91543365e-01, -2.50837113e-01, -7.30371355e-01],\n",
       "        [-1.86757167e-01,  2.04167053e-02, -4.20472639e-01, ...,\n",
       "         -6.45690370e-01, -1.85106045e-01, -3.39612897e-01],\n",
       "        ...,\n",
       "        [-8.95425926e-01,  9.27001518e-01, -2.30120292e-01, ...,\n",
       "          5.17276271e-01, -9.61746937e-01, -2.34628751e-01],\n",
       "        [-8.27941491e-01,  7.75734020e-01, -2.41032913e-01, ...,\n",
       "         -4.35922181e-01, -1.03758902e+00, -5.21911629e-01],\n",
       "        [-9.90258257e-01,  8.86551266e-01, -5.43131051e-01, ...,\n",
       "         -9.71533419e-01, -1.26069151e+00, -6.74849604e-01]],\n",
       "\n",
       "       [[ 1.27620053e+00,  1.02151463e+00, -1.81685460e+00, ...,\n",
       "         -1.56056774e+00, -1.29049560e+00, -1.10462495e+00],\n",
       "        [ 1.91133981e+00, -2.95863846e-01, -7.25485833e-01, ...,\n",
       "         -2.64510390e+00, -1.35901883e+00, -1.63381166e+00],\n",
       "        [ 9.65586904e-01, -9.59395733e-01, -3.25459627e-01, ...,\n",
       "         -2.12805101e+00, -1.76594402e+00, -3.90817817e-01],\n",
       "...\n",
       "        [ 1.67538293e-01, -2.06169238e-01,  7.16212495e-01, ...,\n",
       "         -3.87131904e-01, -9.77682499e-02,  4.38739303e-01],\n",
       "        [ 2.48287200e-01, -8.55439342e-02,  7.79705614e-01, ...,\n",
       "         -3.52362688e-01,  1.05727347e-01,  4.35295684e-01],\n",
       "        [ 1.99468895e-01, -8.62287564e-02,  9.38160889e-01, ...,\n",
       "         -3.55865449e-01,  3.45736801e-01,  4.89451156e-01]],\n",
       "\n",
       "       [[-2.50150520e-01, -6.87843058e-02, -7.37521323e-02, ...,\n",
       "         -1.57742590e+00, -3.11012437e+00, -2.08849377e-01],\n",
       "        [-5.59610990e-01,  1.31475643e+00,  1.13463066e+00, ...,\n",
       "          4.75671981e-01, -4.30557120e-01,  5.81532752e-01],\n",
       "        [ 7.17756255e-01,  1.44361107e+00,  3.51273401e-01, ...,\n",
       "          1.03740257e+00, -2.88860295e-02, -7.96719201e-01],\n",
       "        ...,\n",
       "        [-1.19300851e-01,  6.08363101e-01,  9.03034158e-01, ...,\n",
       "         -2.84023610e-01, -6.70062590e-02,  7.20343371e-01],\n",
       "        [-5.60094173e-02,  2.65321397e-01,  6.43879182e-01, ...,\n",
       "         -3.29366288e-01,  4.47337017e-02,  2.73048754e-01],\n",
       "        [-2.03685595e-01,  2.30178227e-01,  8.03178039e-01, ...,\n",
       "         -6.23034482e-01,  7.64283630e-02,  2.58570232e-01]]])\n",
       "Coordinates: (12/28)\n",
       "  * frequency           (frequency) float64 2.0 2.534 3.212 ... 142.0 180.0\n",
       "  * channel             (channel) object 'E1' 'E10' 'E100' ... 'E97' 'E98' 'E99'\n",
       "    samplerate          float64 500.0\n",
       "  * event               (event) object MultiIndex\n",
       "  * begin_distractor    (event) int64 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0\n",
       "  * begin_math_correct  (event) int64 -999 -999 -999 -999 ... -999 -999 -999\n",
       "    ...                  ...\n",
       "  * rectime             (event) int64 -999 -999 -999 -999 ... -999 -999 -999\n",
       "  * serialpos           (event) int64 1 2 3 4 5 6 7 8 ... 18 19 20 21 22 23 24\n",
       "  * session             (event) int64 0 0 0 0 0 0 0 0 ... 23 23 23 23 23 23 23\n",
       "  * subject             (event) object 'LTP093' 'LTP093' ... 'LTP093' 'LTP093'\n",
       "  * trial               (event) int64 1 1 1 1 1 1 1 1 ... 24 24 24 24 24 24 24\n",
       "  * type                (event) object 'WORD' 'WORD' 'WORD' ... 'WORD' 'WORD'\n",
       "Attributes:\n",
       "    rel_start:    200\n",
       "    rel_stop:     1600\n",
       "    buffer_time:  1000\n",
       "    freqs:        [  2.           2.53445663   3.21173521   4.07000181   5.15...\n",
       "    width:        4\n",
       "    experiment:   ltpFR2\n",
       "    clean:        1\n",
       "    save:         1\n",
       "    reference:    average\n",
       "    cap_type:     EGI"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.unstack(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6157ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_npy = ts.data\n",
    "y_npy = ts.recalled.data\n",
    "X = torch.tensor(ts.data).float()\n",
    "y = torch.tensor(ts.recalled.data).float()\n",
    "dataset = SimpleDataset(X, y)\n",
    "sessions = ts.session.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ef939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 56 has been set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc336425ff954bae9e575644f9a97663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "SESSION 0\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.745432  [    0/12672]\n",
      "loss: 1.996793  [ 1600/12672]\n",
      "loss: 2.304743  [ 3200/12672]\n",
      "loss: 2.183406  [ 4800/12672]\n",
      "loss: 1.957629  [ 6400/12672]\n",
      "loss: 1.758837  [ 8000/12672]\n",
      "loss: 1.953741  [ 9600/12672]\n",
      "loss: 2.101884  [11200/12672]\n",
      "AUC: 0.5432395074139231\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.437188  [    0/12672]\n",
      "loss: 2.152052  [ 1600/12672]\n",
      "loss: 1.826231  [ 3200/12672]\n",
      "loss: 2.456435  [ 4800/12672]\n",
      "loss: 1.164517  [ 6400/12672]\n",
      "loss: 2.500187  [ 8000/12672]\n",
      "loss: 2.419441  [ 9600/12672]\n",
      "loss: 1.984975  [11200/12672]\n",
      "AUC: 0.541090726313144\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.699327  [    0/12672]\n",
      "loss: 2.364421  [ 1600/12672]\n",
      "loss: 2.032473  [ 3200/12672]\n",
      "loss: 2.365137  [ 4800/12672]\n",
      "loss: 2.494399  [ 6400/12672]\n",
      "loss: 2.304005  [ 8000/12672]\n",
      "loss: 3.020437  [ 9600/12672]\n",
      "loss: 2.550306  [11200/12672]\n",
      "AUC: 0.5503895451118372\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.449300  [    0/12672]\n",
      "loss: 2.765722  [ 1600/12672]\n",
      "loss: 2.543235  [ 3200/12672]\n",
      "loss: 1.866425  [ 4800/12672]\n",
      "loss: 1.688641  [ 6400/12672]\n",
      "loss: 2.720394  [ 8000/12672]\n",
      "loss: 2.484617  [ 9600/12672]\n",
      "loss: 3.257766  [11200/12672]\n",
      "AUC: 0.5263885398341291\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 6.329540  [    0/12672]\n",
      "loss: 2.524056  [ 1600/12672]\n",
      "loss: 4.279720  [ 3200/12672]\n",
      "loss: 2.096517  [ 4800/12672]\n",
      "loss: 3.524107  [ 6400/12672]\n",
      "loss: 2.260773  [ 8000/12672]\n",
      "loss: 2.853966  [ 9600/12672]\n",
      "loss: 2.582156  [11200/12672]\n",
      "AUC: 0.546695149535059\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.468516  [    0/12672]\n",
      "loss: 0.700708  [ 1600/12672]\n",
      "loss: 0.693528  [ 3200/12672]\n",
      "loss: 0.676130  [ 4800/12672]\n",
      "loss: 0.694968  [ 6400/12672]\n",
      "loss: 0.671512  [ 8000/12672]\n",
      "loss: 0.683493  [ 9600/12672]\n",
      "loss: 0.671536  [11200/12672]\n",
      "AUC: 0.6171525508921839\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.666215  [    0/12672]\n",
      "loss: 0.688777  [ 1600/12672]\n",
      "loss: 0.687132  [ 3200/12672]\n",
      "loss: 0.677501  [ 4800/12672]\n",
      "loss: 0.675480  [ 6400/12672]\n",
      "loss: 0.675956  [ 8000/12672]\n",
      "loss: 0.695382  [ 9600/12672]\n",
      "loss: 0.682303  [11200/12672]\n",
      "AUC: 0.6143000753958281\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.687447  [    0/12672]\n",
      "loss: 0.692019  [ 1600/12672]\n",
      "loss: 0.673352  [ 3200/12672]\n",
      "loss: 0.676433  [ 4800/12672]\n",
      "loss: 0.689189  [ 6400/12672]\n",
      "loss: 0.680461  [ 8000/12672]\n",
      "loss: 0.682965  [ 9600/12672]\n",
      "loss: 0.665656  [11200/12672]\n",
      "AUC: 0.5736365921085701\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.708215  [    0/12672]\n",
      "loss: 0.692008  [ 1600/12672]\n",
      "loss: 0.667009  [ 3200/12672]\n",
      "loss: 0.675288  [ 4800/12672]\n",
      "loss: 0.685143  [ 6400/12672]\n",
      "loss: 0.686183  [ 8000/12672]\n",
      "loss: 0.710645  [ 9600/12672]\n",
      "loss: 0.694424  [11200/12672]\n",
      "AUC: 0.5950741392309625\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.675857  [    0/12672]\n",
      "loss: 0.679456  [ 1600/12672]\n",
      "loss: 0.688708  [ 3200/12672]\n",
      "loss: 0.684154  [ 4800/12672]\n",
      "loss: 0.671024  [ 6400/12672]\n",
      "loss: 0.689410  [ 8000/12672]\n",
      "loss: 0.671227  [ 9600/12672]\n",
      "loss: 0.672702  [11200/12672]\n",
      "AUC: 0.6253706961548128\n",
      "sklearn AUC: 0.6258356370947475\n",
      "##############################\n",
      "SESSION 1\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.764890  [    0/12672]\n",
      "loss: 1.699614  [ 1600/12672]\n",
      "loss: 2.843538  [ 3200/12672]\n",
      "loss: 2.596693  [ 4800/12672]\n",
      "loss: 2.349087  [ 6400/12672]\n",
      "loss: 2.115015  [ 8000/12672]\n",
      "loss: 3.267020  [ 9600/12672]\n",
      "loss: 2.801669  [11200/12672]\n",
      "AUC: 0.5668518335230366\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 4.048387  [    0/12672]\n",
      "loss: 2.102696  [ 1600/12672]\n",
      "loss: 2.381750  [ 3200/12672]\n",
      "loss: 3.075911  [ 4800/12672]\n",
      "loss: 2.420285  [ 6400/12672]\n",
      "loss: 2.314468  [ 8000/12672]\n",
      "loss: 2.324986  [ 9600/12672]\n",
      "loss: 2.283111  [11200/12672]\n",
      "AUC: 0.5701922601078835\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.972909  [    0/12672]\n",
      "loss: 2.961524  [ 1600/12672]\n",
      "loss: 2.060566  [ 3200/12672]\n",
      "loss: 1.595026  [ 4800/12672]\n",
      "loss: 1.750460  [ 6400/12672]\n",
      "loss: 2.630781  [ 8000/12672]\n",
      "loss: 2.836313  [ 9600/12672]\n",
      "loss: 2.902060  [11200/12672]\n",
      "AUC: 0.576668976097392\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.608702  [    0/12672]\n",
      "loss: 3.112134  [ 1600/12672]\n",
      "loss: 2.329412  [ 3200/12672]\n",
      "loss: 2.626973  [ 4800/12672]\n",
      "loss: 2.032738  [ 6400/12672]\n",
      "loss: 4.033308  [ 8000/12672]\n",
      "loss: 2.890341  [ 9600/12672]\n",
      "loss: 2.568099  [11200/12672]\n",
      "AUC: 0.5688870193497302\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.880482  [    0/12672]\n",
      "loss: 2.171638  [ 1600/12672]\n",
      "loss: 2.713228  [ 3200/12672]\n",
      "loss: 3.809373  [ 4800/12672]\n",
      "loss: 2.326963  [ 6400/12672]\n",
      "loss: 3.175326  [ 8000/12672]\n",
      "loss: 3.685014  [ 9600/12672]\n",
      "loss: 2.164324  [11200/12672]\n",
      "AUC: 0.5632330380561191\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 5.477713  [    0/12672]\n",
      "loss: 0.849035  [ 1600/12672]\n",
      "loss: 0.680370  [ 3200/12672]\n",
      "loss: 0.677624  [ 4800/12672]\n",
      "loss: 0.692802  [ 6400/12672]\n",
      "loss: 0.681994  [ 8000/12672]\n",
      "loss: 0.692542  [ 9600/12672]\n",
      "loss: 0.689597  [11200/12672]\n",
      "AUC: 0.532587717127728\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.676002  [    0/12672]\n",
      "loss: 0.686502  [ 1600/12672]\n",
      "loss: 0.693829  [ 3200/12672]\n",
      "loss: 0.684957  [ 4800/12672]\n",
      "loss: 0.682206  [ 6400/12672]\n",
      "loss: 0.684260  [ 8000/12672]\n",
      "loss: 0.676919  [ 9600/12672]\n",
      "loss: 0.686794  [11200/12672]\n",
      "AUC: 0.6076359677339537\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.685750  [    0/12672]\n",
      "loss: 0.685233  [ 1600/12672]\n",
      "loss: 0.675762  [ 3200/12672]\n",
      "loss: 0.669533  [ 4800/12672]\n",
      "loss: 0.684903  [ 6400/12672]\n",
      "loss: 0.675842  [ 8000/12672]\n",
      "loss: 0.681250  [ 9600/12672]\n",
      "loss: 0.677913  [11200/12672]\n",
      "AUC: 0.6129311624684516\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.689328  [    0/12672]\n",
      "loss: 0.679829  [ 1600/12672]\n",
      "loss: 0.682610  [ 3200/12672]\n",
      "loss: 0.682198  [ 4800/12672]\n",
      "loss: 0.673650  [ 6400/12672]\n",
      "loss: 0.689382  [ 8000/12672]\n",
      "loss: 0.684419  [ 9600/12672]\n",
      "loss: 0.684210  [11200/12672]\n",
      "AUC: 0.5908224872568912\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.676694  [    0/12672]\n",
      "loss: 0.677989  [ 1600/12672]\n",
      "loss: 0.673105  [ 3200/12672]\n",
      "loss: 0.682267  [ 4800/12672]\n",
      "loss: 0.668386  [ 6400/12672]\n",
      "loss: 0.684440  [ 8000/12672]\n",
      "loss: 0.675687  [ 9600/12672]\n",
      "loss: 0.676692  [11200/12672]\n",
      "AUC: 0.5876923838273866\n",
      "sklearn AUC: 0.5777453357747315\n",
      "##############################\n",
      "SESSION 2\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.733132  [    0/12672]\n",
      "loss: 1.918195  [ 1600/12672]\n",
      "loss: 3.047584  [ 3200/12672]\n",
      "loss: 3.054600  [ 4800/12672]\n",
      "loss: 3.412297  [ 6400/12672]\n",
      "loss: 3.049307  [ 8000/12672]\n",
      "loss: 2.413154  [ 9600/12672]\n",
      "loss: 2.048525  [11200/12672]\n",
      "AUC: 0.4878721859114016\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.471427  [    0/12672]\n",
      "loss: 2.409298  [ 1600/12672]\n",
      "loss: 2.165976  [ 3200/12672]\n",
      "loss: 1.732591  [ 4800/12672]\n",
      "loss: 3.022880  [ 6400/12672]\n",
      "loss: 2.046564  [ 8000/12672]\n",
      "loss: 1.746551  [ 9600/12672]\n",
      "loss: 1.880523  [11200/12672]\n",
      "AUC: 0.4860566448801743\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.700447  [    0/12672]\n",
      "loss: 2.972633  [ 1600/12672]\n",
      "loss: 2.266039  [ 3200/12672]\n",
      "loss: 2.208823  [ 4800/12672]\n",
      "loss: 3.655629  [ 6400/12672]\n",
      "loss: 2.606248  [ 8000/12672]\n",
      "loss: 3.318285  [ 9600/12672]\n",
      "loss: 2.228842  [11200/12672]\n",
      "AUC: 0.48592350520455097\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.304882  [    0/12672]\n",
      "loss: 2.200992  [ 1600/12672]\n",
      "loss: 3.365231  [ 3200/12672]\n",
      "loss: 2.145385  [ 4800/12672]\n",
      "loss: 3.006649  [ 6400/12672]\n",
      "loss: 1.878996  [ 8000/12672]\n",
      "loss: 2.880288  [ 9600/12672]\n",
      "loss: 2.489501  [11200/12672]\n",
      "AUC: 0.4774086177680949\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.978452  [    0/12672]\n",
      "loss: 2.072610  [ 1600/12672]\n",
      "loss: 4.882101  [ 3200/12672]\n",
      "loss: 2.138558  [ 4800/12672]\n",
      "loss: 1.765347  [ 6400/12672]\n",
      "loss: 1.620879  [ 8000/12672]\n",
      "loss: 2.584701  [ 9600/12672]\n",
      "loss: 2.903093  [11200/12672]\n",
      "AUC: 0.4807007988380537\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.199480  [    0/12672]\n",
      "loss: 0.690443  [ 1600/12672]\n",
      "loss: 0.695056  [ 3200/12672]\n",
      "loss: 0.674293  [ 4800/12672]\n",
      "loss: 0.676909  [ 6400/12672]\n",
      "loss: 0.676827  [ 8000/12672]\n",
      "loss: 0.704472  [ 9600/12672]\n",
      "loss: 0.666424  [11200/12672]\n",
      "AUC: 0.5320624546114742\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.690030  [    0/12672]\n",
      "loss: 0.683837  [ 1600/12672]\n",
      "loss: 0.680126  [ 3200/12672]\n",
      "loss: 0.708632  [ 4800/12672]\n",
      "loss: 0.675494  [ 6400/12672]\n",
      "loss: 0.676944  [ 8000/12672]\n",
      "loss: 0.684855  [ 9600/12672]\n",
      "loss: 0.670525  [11200/12672]\n",
      "AUC: 0.5330549503752118\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.671289  [    0/12672]\n",
      "loss: 0.688272  [ 1600/12672]\n",
      "loss: 0.673063  [ 3200/12672]\n",
      "loss: 0.676546  [ 4800/12672]\n",
      "loss: 0.687089  [ 6400/12672]\n",
      "loss: 0.690334  [ 8000/12672]\n",
      "loss: 0.693224  [ 9600/12672]\n",
      "loss: 0.682850  [11200/12672]\n",
      "AUC: 0.49094650205761314\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.703500  [    0/12672]\n",
      "loss: 0.678979  [ 1600/12672]\n",
      "loss: 0.688859  [ 3200/12672]\n",
      "loss: 0.673834  [ 4800/12672]\n",
      "loss: 0.684518  [ 6400/12672]\n",
      "loss: 0.687478  [ 8000/12672]\n",
      "loss: 0.681975  [ 9600/12672]\n",
      "loss: 0.685575  [11200/12672]\n",
      "AUC: 0.5204429920116194\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.687446  [    0/12672]\n",
      "loss: 0.680335  [ 1600/12672]\n",
      "loss: 0.691870  [ 3200/12672]\n",
      "loss: 0.683889  [ 4800/12672]\n",
      "loss: 0.682253  [ 6400/12672]\n",
      "loss: 0.680740  [ 8000/12672]\n",
      "loss: 0.674920  [ 9600/12672]\n",
      "loss: 0.680277  [11200/12672]\n",
      "AUC: 0.529520697167756\n",
      "sklearn AUC: 0.5289881384652626\n",
      "##############################\n",
      "SESSION 3\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.753539  [    0/12672]\n",
      "loss: 2.460051  [ 1600/12672]\n",
      "loss: 1.977108  [ 3200/12672]\n",
      "loss: 2.592093  [ 4800/12672]\n",
      "loss: 2.019945  [ 6400/12672]\n",
      "loss: 2.326581  [ 8000/12672]\n",
      "loss: 2.854949  [ 9600/12672]\n",
      "loss: 2.872136  [11200/12672]\n",
      "AUC: 0.5102905273437499\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.920854  [    0/12672]\n",
      "loss: 3.044145  [ 1600/12672]\n",
      "loss: 2.334139  [ 3200/12672]\n",
      "loss: 1.680641  [ 4800/12672]\n",
      "loss: 1.828277  [ 6400/12672]\n",
      "loss: 1.674152  [ 8000/12672]\n",
      "loss: 2.132528  [ 9600/12672]\n",
      "loss: 2.028266  [11200/12672]\n",
      "AUC: 0.504833984375\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.707968  [    0/12672]\n",
      "loss: 2.353799  [ 1600/12672]\n",
      "loss: 1.415029  [ 3200/12672]\n",
      "loss: 1.519116  [ 4800/12672]\n",
      "loss: 3.204559  [ 6400/12672]\n",
      "loss: 1.984975  [ 8000/12672]\n",
      "loss: 2.920211  [ 9600/12672]\n",
      "loss: 2.600893  [11200/12672]\n",
      "AUC: 0.51971435546875\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.499947  [    0/12672]\n",
      "loss: 2.287203  [ 1600/12672]\n",
      "loss: 2.093975  [ 3200/12672]\n",
      "loss: 2.035944  [ 4800/12672]\n",
      "loss: 2.086893  [ 6400/12672]\n",
      "loss: 2.824918  [ 8000/12672]\n",
      "loss: 2.359528  [ 9600/12672]\n",
      "loss: 2.909451  [11200/12672]\n",
      "AUC: 0.5173583984375001\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.701330  [    0/12672]\n",
      "loss: 2.254435  [ 1600/12672]\n",
      "loss: 1.905162  [ 3200/12672]\n",
      "loss: 2.256475  [ 4800/12672]\n",
      "loss: 2.370613  [ 6400/12672]\n",
      "loss: 2.625518  [ 8000/12672]\n",
      "loss: 2.395669  [ 9600/12672]\n",
      "loss: 1.945459  [11200/12672]\n",
      "AUC: 0.5186767578125\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.287862  [    0/12672]\n",
      "loss: 0.701449  [ 1600/12672]\n",
      "loss: 0.693141  [ 3200/12672]\n",
      "loss: 0.690194  [ 4800/12672]\n",
      "loss: 0.690271  [ 6400/12672]\n",
      "loss: 0.689042  [ 8000/12672]\n",
      "loss: 0.679337  [ 9600/12672]\n",
      "loss: 0.679634  [11200/12672]\n",
      "AUC: 0.57864990234375\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.687339  [    0/12672]\n",
      "loss: 0.691344  [ 1600/12672]\n",
      "loss: 0.665609  [ 3200/12672]\n",
      "loss: 0.686292  [ 4800/12672]\n",
      "loss: 0.662482  [ 6400/12672]\n",
      "loss: 0.682026  [ 8000/12672]\n",
      "loss: 0.677222  [ 9600/12672]\n",
      "loss: 0.672027  [11200/12672]\n",
      "AUC: 0.5573974609375\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.700365  [    0/12672]\n",
      "loss: 0.673137  [ 1600/12672]\n",
      "loss: 0.673426  [ 3200/12672]\n",
      "loss: 0.671762  [ 4800/12672]\n",
      "loss: 0.673527  [ 6400/12672]\n",
      "loss: 0.688960  [ 8000/12672]\n",
      "loss: 0.677180  [ 9600/12672]\n",
      "loss: 0.685111  [11200/12672]\n",
      "AUC: 0.61005859375\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.680067  [    0/12672]\n",
      "loss: 0.691378  [ 1600/12672]\n",
      "loss: 0.677288  [ 3200/12672]\n",
      "loss: 0.686132  [ 4800/12672]\n",
      "loss: 0.687478  [ 6400/12672]\n",
      "loss: 0.678615  [ 8000/12672]\n",
      "loss: 0.670937  [ 9600/12672]\n",
      "loss: 0.692898  [11200/12672]\n",
      "AUC: 0.5777587890625\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.681829  [    0/12672]\n",
      "loss: 0.689682  [ 1600/12672]\n",
      "loss: 0.675714  [ 3200/12672]\n",
      "loss: 0.677650  [ 4800/12672]\n",
      "loss: 0.681353  [ 6400/12672]\n",
      "loss: 0.671684  [ 8000/12672]\n",
      "loss: 0.674690  [ 9600/12672]\n",
      "loss: 0.687045  [11200/12672]\n",
      "AUC: 0.597314453125\n",
      "sklearn AUC: 0.59306640625\n",
      "##############################\n",
      "SESSION 4\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.760653  [    0/12672]\n",
      "loss: 1.781553  [ 1600/12672]\n",
      "loss: 2.110374  [ 3200/12672]\n",
      "loss: 3.208347  [ 4800/12672]\n",
      "loss: 2.892700  [ 6400/12672]\n",
      "loss: 2.162598  [ 8000/12672]\n",
      "loss: 2.221037  [ 9600/12672]\n",
      "loss: 3.053047  [11200/12672]\n",
      "AUC: 0.42619332909473273\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.114813  [    0/12672]\n",
      "loss: 1.901425  [ 1600/12672]\n",
      "loss: 1.993603  [ 3200/12672]\n",
      "loss: 2.900810  [ 4800/12672]\n",
      "loss: 3.299648  [ 6400/12672]\n",
      "loss: 2.352026  [ 8000/12672]\n",
      "loss: 2.076504  [ 9600/12672]\n",
      "loss: 2.723894  [11200/12672]\n",
      "AUC: 0.42245806230742894\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.309948  [    0/12672]\n",
      "loss: 1.898982  [ 1600/12672]\n",
      "loss: 2.402706  [ 3200/12672]\n",
      "loss: 3.723909  [ 4800/12672]\n",
      "loss: 2.418113  [ 6400/12672]\n",
      "loss: 2.136762  [ 8000/12672]\n",
      "loss: 5.975776  [ 9600/12672]\n",
      "loss: 2.204949  [11200/12672]\n",
      "AUC: 0.42617498899594075\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.612441  [    0/12672]\n",
      "loss: 2.925276  [ 1600/12672]\n",
      "loss: 3.340799  [ 3200/12672]\n",
      "loss: 1.863398  [ 4800/12672]\n",
      "loss: 4.549306  [ 6400/12672]\n",
      "loss: 2.451219  [ 8000/12672]\n",
      "loss: 2.303280  [ 9600/12672]\n",
      "loss: 2.295763  [11200/12672]\n",
      "AUC: 0.4251479434635888\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.668925  [    0/12672]\n",
      "loss: 2.282473  [ 1600/12672]\n",
      "loss: 2.609217  [ 3200/12672]\n",
      "loss: 4.600268  [ 4800/12672]\n",
      "loss: 3.171481  [ 6400/12672]\n",
      "loss: 2.540161  [ 8000/12672]\n",
      "loss: 2.973692  [ 9600/12672]\n",
      "loss: 2.739087  [11200/12672]\n",
      "AUC: 0.44440504719518753\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.388601  [    0/12672]\n",
      "loss: 0.731104  [ 1600/12672]\n",
      "loss: 0.709865  [ 3200/12672]\n",
      "loss: 0.682690  [ 4800/12672]\n",
      "loss: 0.688603  [ 6400/12672]\n",
      "loss: 0.683230  [ 8000/12672]\n",
      "loss: 0.694795  [ 9600/12672]\n",
      "loss: 0.679983  [11200/12672]\n",
      "AUC: 0.5276690957108623\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.686509  [    0/12672]\n",
      "loss: 0.675255  [ 1600/12672]\n",
      "loss: 0.688427  [ 3200/12672]\n",
      "loss: 0.694038  [ 4800/12672]\n",
      "loss: 0.675750  [ 6400/12672]\n",
      "loss: 0.688103  [ 8000/12672]\n",
      "loss: 0.682250  [ 9600/12672]\n",
      "loss: 0.670761  [11200/12672]\n",
      "AUC: 0.5368024649092776\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.692459  [    0/12672]\n",
      "loss: 0.687330  [ 1600/12672]\n",
      "loss: 0.678787  [ 3200/12672]\n",
      "loss: 0.685304  [ 4800/12672]\n",
      "loss: 0.678705  [ 6400/12672]\n",
      "loss: 0.698699  [ 8000/12672]\n",
      "loss: 0.676828  [ 9600/12672]\n",
      "loss: 0.674504  [11200/12672]\n",
      "AUC: 0.5269966254218222\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.668795  [    0/12672]\n",
      "loss: 0.706875  [ 1600/12672]\n",
      "loss: 0.677813  [ 3200/12672]\n",
      "loss: 0.669793  [ 4800/12672]\n",
      "loss: 0.686868  [ 6400/12672]\n",
      "loss: 0.680091  [ 8000/12672]\n",
      "loss: 0.682871  [ 9600/12672]\n",
      "loss: 0.695258  [11200/12672]\n",
      "AUC: 0.5442363182863011\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.678372  [    0/12672]\n",
      "loss: 0.679214  [ 1600/12672]\n",
      "loss: 0.680534  [ 3200/12672]\n",
      "loss: 0.687452  [ 4800/12672]\n",
      "loss: 0.683290  [ 6400/12672]\n",
      "loss: 0.666775  [ 8000/12672]\n",
      "loss: 0.681309  [ 9600/12672]\n",
      "loss: 0.690107  [11200/12672]\n",
      "AUC: 0.5247346799041425\n",
      "sklearn AUC: 0.500831417811904\n",
      "##############################\n",
      "SESSION 5\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.704859  [    0/12672]\n",
      "loss: 3.383421  [ 1600/12672]\n",
      "loss: 1.614233  [ 3200/12672]\n",
      "loss: 2.171172  [ 4800/12672]\n",
      "loss: 2.248076  [ 6400/12672]\n",
      "loss: 1.700836  [ 8000/12672]\n",
      "loss: 2.518138  [ 9600/12672]\n",
      "loss: 1.911641  [11200/12672]\n",
      "AUC: 0.510408856900085\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.545510  [    0/12672]\n",
      "loss: 1.998750  [ 1600/12672]\n",
      "loss: 1.866885  [ 3200/12672]\n",
      "loss: 4.068071  [ 4800/12672]\n",
      "loss: 1.966159  [ 6400/12672]\n",
      "loss: 2.277544  [ 8000/12672]\n",
      "loss: 2.529150  [ 9600/12672]\n",
      "loss: 2.289493  [11200/12672]\n",
      "AUC: 0.48473034437946716\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.188185  [    0/12672]\n",
      "loss: 3.683742  [ 1600/12672]\n",
      "loss: 3.898065  [ 3200/12672]\n",
      "loss: 1.889963  [ 4800/12672]\n",
      "loss: 2.699161  [ 6400/12672]\n",
      "loss: 1.376885  [ 8000/12672]\n",
      "loss: 4.347106  [ 9600/12672]\n",
      "loss: 3.142018  [11200/12672]\n",
      "AUC: 0.5059854051082121\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.070385  [    0/12672]\n",
      "loss: 2.473736  [ 1600/12672]\n",
      "loss: 2.452034  [ 3200/12672]\n",
      "loss: 3.454297  [ 4800/12672]\n",
      "loss: 1.695019  [ 6400/12672]\n",
      "loss: 3.251040  [ 8000/12672]\n",
      "loss: 2.852823  [ 9600/12672]\n",
      "loss: 3.939052  [11200/12672]\n",
      "AUC: 0.47542735042735046\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 5.637913  [    0/12672]\n",
      "loss: 2.840919  [ 1600/12672]\n",
      "loss: 3.388091  [ 3200/12672]\n",
      "loss: 2.023268  [ 4800/12672]\n",
      "loss: 1.670656  [ 6400/12672]\n",
      "loss: 2.765919  [ 8000/12672]\n",
      "loss: 2.868331  [ 9600/12672]\n",
      "loss: 3.057916  [11200/12672]\n",
      "AUC: 0.47850752236717153\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 4.455945  [    0/12672]\n",
      "loss: 0.716985  [ 1600/12672]\n",
      "loss: 0.664755  [ 3200/12672]\n",
      "loss: 0.681020  [ 4800/12672]\n",
      "loss: 0.684838  [ 6400/12672]\n",
      "loss: 0.671914  [ 8000/12672]\n",
      "loss: 0.685748  [ 9600/12672]\n",
      "loss: 0.694226  [11200/12672]\n",
      "AUC: 0.5583170890188435\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.672903  [    0/12672]\n",
      "loss: 0.676897  [ 1600/12672]\n",
      "loss: 0.677917  [ 3200/12672]\n",
      "loss: 0.683701  [ 4800/12672]\n",
      "loss: 0.679582  [ 6400/12672]\n",
      "loss: 0.692583  [ 8000/12672]\n",
      "loss: 0.678020  [ 9600/12672]\n",
      "loss: 0.697557  [11200/12672]\n",
      "AUC: 0.5613910131453991\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.691479  [    0/12672]\n",
      "loss: 0.676927  [ 1600/12672]\n",
      "loss: 0.671722  [ 3200/12672]\n",
      "loss: 0.690084  [ 4800/12672]\n",
      "loss: 0.677052  [ 6400/12672]\n",
      "loss: 0.681956  [ 8000/12672]\n",
      "loss: 0.692742  [ 9600/12672]\n",
      "loss: 0.688956  [11200/12672]\n",
      "AUC: 0.5741740390863197\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.688335  [    0/12672]\n",
      "loss: 0.688997  [ 1600/12672]\n",
      "loss: 0.669995  [ 3200/12672]\n",
      "loss: 0.686704  [ 4800/12672]\n",
      "loss: 0.678379  [ 6400/12672]\n",
      "loss: 0.683174  [ 8000/12672]\n",
      "loss: 0.695545  [ 9600/12672]\n",
      "loss: 0.680485  [11200/12672]\n",
      "AUC: 0.5497076023391814\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.682228  [    0/12672]\n",
      "loss: 0.681754  [ 1600/12672]\n",
      "loss: 0.665759  [ 3200/12672]\n",
      "loss: 0.699880  [ 4800/12672]\n",
      "loss: 0.680377  [ 6400/12672]\n",
      "loss: 0.672390  [ 8000/12672]\n",
      "loss: 0.680447  [ 9600/12672]\n",
      "loss: 0.683104  [11200/12672]\n",
      "AUC: 0.5580546808616984\n",
      "sklearn AUC: 0.5709626630679263\n",
      "##############################\n",
      "SESSION 6\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.733163  [    0/12672]\n",
      "loss: 1.410591  [ 1600/12672]\n",
      "loss: 2.152969  [ 3200/12672]\n",
      "loss: 2.699235  [ 4800/12672]\n",
      "loss: 3.983548  [ 6400/12672]\n",
      "loss: 2.514612  [ 8000/12672]\n",
      "loss: 3.189413  [ 9600/12672]\n",
      "loss: 2.309278  [11200/12672]\n",
      "AUC: 0.48241245417711753\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.802881  [    0/12672]\n",
      "loss: 4.057206  [ 1600/12672]\n",
      "loss: 3.129144  [ 3200/12672]\n",
      "loss: 2.740271  [ 4800/12672]\n",
      "loss: 1.995210  [ 6400/12672]\n",
      "loss: 2.248213  [ 8000/12672]\n",
      "loss: 2.138072  [ 9600/12672]\n",
      "loss: 2.445448  [11200/12672]\n",
      "AUC: 0.4854693227860313\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.546207  [    0/12672]\n",
      "loss: 3.091577  [ 1600/12672]\n",
      "loss: 3.579604  [ 3200/12672]\n",
      "loss: 2.852892  [ 4800/12672]\n",
      "loss: 3.119250  [ 6400/12672]\n",
      "loss: 1.806231  [ 8000/12672]\n",
      "loss: 2.377734  [ 9600/12672]\n",
      "loss: 3.098856  [11200/12672]\n",
      "AUC: 0.47180686860891374\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.237097  [    0/12672]\n",
      "loss: 2.790263  [ 1600/12672]\n",
      "loss: 3.941064  [ 3200/12672]\n",
      "loss: 3.054617  [ 4800/12672]\n",
      "loss: 2.000910  [ 6400/12672]\n",
      "loss: 1.908430  [ 8000/12672]\n",
      "loss: 3.308382  [ 9600/12672]\n",
      "loss: 2.202774  [11200/12672]\n",
      "AUC: 0.4884839861084314\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.560836  [    0/12672]\n",
      "loss: 3.477830  [ 1600/12672]\n",
      "loss: 2.681397  [ 3200/12672]\n",
      "loss: 2.346396  [ 4800/12672]\n",
      "loss: 2.487808  [ 6400/12672]\n",
      "loss: 5.215377  [ 8000/12672]\n",
      "loss: 2.258996  [ 9600/12672]\n",
      "loss: 2.197780  [11200/12672]\n",
      "AUC: 0.48020572062512057\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.999564  [    0/12672]\n",
      "loss: 0.686576  [ 1600/12672]\n",
      "loss: 0.681865  [ 3200/12672]\n",
      "loss: 0.692258  [ 4800/12672]\n",
      "loss: 0.685926  [ 6400/12672]\n",
      "loss: 0.674179  [ 8000/12672]\n",
      "loss: 0.674641  [ 9600/12672]\n",
      "loss: 0.681835  [11200/12672]\n",
      "AUC: 0.5247443565502605\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.689862  [    0/12672]\n",
      "loss: 0.686598  [ 1600/12672]\n",
      "loss: 0.679347  [ 3200/12672]\n",
      "loss: 0.686002  [ 4800/12672]\n",
      "loss: 0.681109  [ 6400/12672]\n",
      "loss: 0.683662  [ 8000/12672]\n",
      "loss: 0.690145  [ 9600/12672]\n",
      "loss: 0.675623  [11200/12672]\n",
      "AUC: 0.5326065984950801\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.691334  [    0/12672]\n",
      "loss: 0.685405  [ 1600/12672]\n",
      "loss: 0.683896  [ 3200/12672]\n",
      "loss: 0.687221  [ 4800/12672]\n",
      "loss: 0.685962  [ 6400/12672]\n",
      "loss: 0.678914  [ 8000/12672]\n",
      "loss: 0.702324  [ 9600/12672]\n",
      "loss: 0.683321  [11200/12672]\n",
      "AUC: 0.5108648466139302\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.674303  [    0/12672]\n",
      "loss: 0.675454  [ 1600/12672]\n",
      "loss: 0.689133  [ 3200/12672]\n",
      "loss: 0.697062  [ 4800/12672]\n",
      "loss: 0.683867  [ 6400/12672]\n",
      "loss: 0.684207  [ 8000/12672]\n",
      "loss: 0.686358  [ 9600/12672]\n",
      "loss: 0.674610  [11200/12672]\n",
      "AUC: 0.500663225930928\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.674615  [    0/12672]\n",
      "loss: 0.677679  [ 1600/12672]\n",
      "loss: 0.689792  [ 3200/12672]\n",
      "loss: 0.685798  [ 4800/12672]\n",
      "loss: 0.675329  [ 6400/12672]\n",
      "loss: 0.670393  [ 8000/12672]\n",
      "loss: 0.687519  [ 9600/12672]\n",
      "loss: 0.681233  [11200/12672]\n",
      "AUC: 0.5064754968165155\n",
      "sklearn AUC: 0.5266134478101485\n",
      "##############################\n",
      "SESSION 7\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.725233  [    0/12672]\n",
      "loss: 2.179183  [ 1600/12672]\n",
      "loss: 1.910993  [ 3200/12672]\n",
      "loss: 2.758301  [ 4800/12672]\n",
      "loss: 2.739532  [ 6400/12672]\n",
      "loss: 2.005902  [ 8000/12672]\n",
      "loss: 2.576463  [ 9600/12672]\n",
      "loss: 2.818312  [11200/12672]\n",
      "AUC: 0.5352272727272727\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.082984  [    0/12672]\n",
      "loss: 2.186601  [ 1600/12672]\n",
      "loss: 2.459157  [ 3200/12672]\n",
      "loss: 2.289084  [ 4800/12672]\n",
      "loss: 1.856130  [ 6400/12672]\n",
      "loss: 2.676562  [ 8000/12672]\n",
      "loss: 3.064371  [ 9600/12672]\n",
      "loss: 2.209818  [11200/12672]\n",
      "AUC: 0.5287538304392236\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.334239  [    0/12672]\n",
      "loss: 2.999068  [ 1600/12672]\n",
      "loss: 2.430852  [ 3200/12672]\n",
      "loss: 2.703245  [ 4800/12672]\n",
      "loss: 2.071851  [ 6400/12672]\n",
      "loss: 1.408194  [ 8000/12672]\n",
      "loss: 1.863741  [ 9600/12672]\n",
      "loss: 1.558187  [11200/12672]\n",
      "AUC: 0.5289964249233912\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.781833  [    0/12672]\n",
      "loss: 2.115752  [ 1600/12672]\n",
      "loss: 1.916286  [ 3200/12672]\n",
      "loss: 2.549547  [ 4800/12672]\n",
      "loss: 2.328056  [ 6400/12672]\n",
      "loss: 2.304892  [ 8000/12672]\n",
      "loss: 2.191816  [ 9600/12672]\n",
      "loss: 2.359732  [11200/12672]\n",
      "AUC: 0.5230911644535239\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 4.322006  [    0/12672]\n",
      "loss: 2.685873  [ 1600/12672]\n",
      "loss: 2.027153  [ 3200/12672]\n",
      "loss: 1.868324  [ 4800/12672]\n",
      "loss: 2.963211  [ 6400/12672]\n",
      "loss: 2.206433  [ 8000/12672]\n",
      "loss: 2.014700  [ 9600/12672]\n",
      "loss: 2.586468  [11200/12672]\n",
      "AUC: 0.5500510725229827\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.438398  [    0/12672]\n",
      "loss: 0.730509  [ 1600/12672]\n",
      "loss: 0.698475  [ 3200/12672]\n",
      "loss: 0.679074  [ 4800/12672]\n",
      "loss: 0.684416  [ 6400/12672]\n",
      "loss: 0.657973  [ 8000/12672]\n",
      "loss: 0.681244  [ 9600/12672]\n",
      "loss: 0.690390  [11200/12672]\n",
      "AUC: 0.6000893769152196\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.684831  [    0/12672]\n",
      "loss: 0.698224  [ 1600/12672]\n",
      "loss: 0.681979  [ 3200/12672]\n",
      "loss: 0.690175  [ 4800/12672]\n",
      "loss: 0.683202  [ 6400/12672]\n",
      "loss: 0.688474  [ 8000/12672]\n",
      "loss: 0.678620  [ 9600/12672]\n",
      "loss: 0.675764  [11200/12672]\n",
      "AUC: 0.5915858018386108\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.681911  [    0/12672]\n",
      "loss: 0.681082  [ 1600/12672]\n",
      "loss: 0.681785  [ 3200/12672]\n",
      "loss: 0.677454  [ 4800/12672]\n",
      "loss: 0.685825  [ 6400/12672]\n",
      "loss: 0.671923  [ 8000/12672]\n",
      "loss: 0.673142  [ 9600/12672]\n",
      "loss: 0.675797  [11200/12672]\n",
      "AUC: 0.5911389172625128\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.686539  [    0/12672]\n",
      "loss: 0.691242  [ 1600/12672]\n",
      "loss: 0.679256  [ 3200/12672]\n",
      "loss: 0.666348  [ 4800/12672]\n",
      "loss: 0.683919  [ 6400/12672]\n",
      "loss: 0.700214  [ 8000/12672]\n",
      "loss: 0.700574  [ 9600/12672]\n",
      "loss: 0.689614  [11200/12672]\n",
      "AUC: 0.5973059244126661\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.672103  [    0/12672]\n",
      "loss: 0.686832  [ 1600/12672]\n",
      "loss: 0.693130  [ 3200/12672]\n",
      "loss: 0.686147  [ 4800/12672]\n",
      "loss: 0.689511  [ 6400/12672]\n",
      "loss: 0.685865  [ 8000/12672]\n",
      "loss: 0.683599  [ 9600/12672]\n",
      "loss: 0.685899  [11200/12672]\n",
      "AUC: 0.6026430030643514\n",
      "sklearn AUC: 0.5945990806945863\n",
      "##############################\n",
      "SESSION 8\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.754130  [    0/12672]\n",
      "loss: 2.541938  [ 1600/12672]\n",
      "loss: 2.402936  [ 3200/12672]\n",
      "loss: 2.746822  [ 4800/12672]\n",
      "loss: 2.332322  [ 6400/12672]\n",
      "loss: 1.426862  [ 8000/12672]\n",
      "loss: 4.481506  [ 9600/12672]\n",
      "loss: 2.180653  [11200/12672]\n",
      "AUC: 0.5359172482552342\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.594851  [    0/12672]\n",
      "loss: 2.657850  [ 1600/12672]\n",
      "loss: 2.898392  [ 3200/12672]\n",
      "loss: 2.311502  [ 4800/12672]\n",
      "loss: 2.142169  [ 6400/12672]\n",
      "loss: 1.681278  [ 8000/12672]\n",
      "loss: 2.287830  [ 9600/12672]\n",
      "loss: 2.845898  [11200/12672]\n",
      "AUC: 0.5350760219341975\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.740412  [    0/12672]\n",
      "loss: 3.469613  [ 1600/12672]\n",
      "loss: 1.845939  [ 3200/12672]\n",
      "loss: 2.899312  [ 4800/12672]\n",
      "loss: 2.321339  [ 6400/12672]\n",
      "loss: 2.412082  [ 8000/12672]\n",
      "loss: 2.153044  [ 9600/12672]\n",
      "loss: 2.018315  [11200/12672]\n",
      "AUC: 0.5310319042871385\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.394260  [    0/12672]\n",
      "loss: 1.594343  [ 1600/12672]\n",
      "loss: 2.372900  [ 3200/12672]\n",
      "loss: 2.009075  [ 4800/12672]\n",
      "loss: 3.095984  [ 6400/12672]\n",
      "loss: 2.571765  [ 8000/12672]\n",
      "loss: 2.510613  [ 9600/12672]\n",
      "loss: 2.210886  [11200/12672]\n",
      "AUC: 0.5322781655034896\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.891382  [    0/12672]\n",
      "loss: 2.285049  [ 1600/12672]\n",
      "loss: 2.072846  [ 3200/12672]\n",
      "loss: 1.897807  [ 4800/12672]\n",
      "loss: 2.236358  [ 6400/12672]\n",
      "loss: 2.987932  [ 8000/12672]\n",
      "loss: 2.308033  [ 9600/12672]\n",
      "loss: 2.433686  [11200/12672]\n",
      "AUC: 0.5520937188434697\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.155593  [    0/12672]\n",
      "loss: 0.704308  [ 1600/12672]\n",
      "loss: 0.695576  [ 3200/12672]\n",
      "loss: 0.671326  [ 4800/12672]\n",
      "loss: 0.678287  [ 6400/12672]\n",
      "loss: 0.682750  [ 8000/12672]\n",
      "loss: 0.682807  [ 9600/12672]\n",
      "loss: 0.684154  [11200/12672]\n",
      "AUC: 0.5629860418743768\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.672543  [    0/12672]\n",
      "loss: 0.679301  [ 1600/12672]\n",
      "loss: 0.665876  [ 3200/12672]\n",
      "loss: 0.677718  [ 4800/12672]\n",
      "loss: 0.674640  [ 6400/12672]\n",
      "loss: 0.687558  [ 8000/12672]\n",
      "loss: 0.677791  [ 9600/12672]\n",
      "loss: 0.686172  [11200/12672]\n",
      "AUC: 0.5828015952143569\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.687678  [    0/12672]\n",
      "loss: 0.693279  [ 1600/12672]\n",
      "loss: 0.684091  [ 3200/12672]\n",
      "loss: 0.678419  [ 4800/12672]\n",
      "loss: 0.670793  [ 6400/12672]\n",
      "loss: 0.684272  [ 8000/12672]\n",
      "loss: 0.677276  [ 9600/12672]\n",
      "loss: 0.694585  [11200/12672]\n",
      "AUC: 0.5601071784646062\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.694842  [    0/12672]\n",
      "loss: 0.693567  [ 1600/12672]\n",
      "loss: 0.673220  [ 3200/12672]\n",
      "loss: 0.685269  [ 4800/12672]\n",
      "loss: 0.680524  [ 6400/12672]\n",
      "loss: 0.666894  [ 8000/12672]\n",
      "loss: 0.672156  [ 9600/12672]\n",
      "loss: 0.671763  [11200/12672]\n",
      "AUC: 0.5728439680957128\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.680717  [    0/12672]\n",
      "loss: 0.675672  [ 1600/12672]\n",
      "loss: 0.684815  [ 3200/12672]\n",
      "loss: 0.688122  [ 4800/12672]\n",
      "loss: 0.691838  [ 6400/12672]\n",
      "loss: 0.678032  [ 8000/12672]\n",
      "loss: 0.682927  [ 9600/12672]\n",
      "loss: 0.673408  [11200/12672]\n",
      "AUC: 0.5719092721834497\n",
      "sklearn AUC: 0.5865777666999004\n",
      "##############################\n",
      "SESSION 9\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.736697  [    0/12672]\n",
      "loss: 1.455632  [ 1600/12672]\n",
      "loss: 2.755514  [ 3200/12672]\n",
      "loss: 1.929578  [ 4800/12672]\n",
      "loss: 3.355920  [ 6400/12672]\n",
      "loss: 2.739186  [ 8000/12672]\n",
      "loss: 3.190937  [ 9600/12672]\n",
      "loss: 2.091282  [11200/12672]\n",
      "AUC: 0.44295199182839634\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.720748  [    0/12672]\n",
      "loss: 3.390157  [ 1600/12672]\n",
      "loss: 2.311866  [ 3200/12672]\n",
      "loss: 1.790423  [ 4800/12672]\n",
      "loss: 2.092279  [ 6400/12672]\n",
      "loss: 1.969910  [ 8000/12672]\n",
      "loss: 3.498100  [ 9600/12672]\n",
      "loss: 2.452907  [11200/12672]\n",
      "AUC: 0.45124489274770163\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 8.293344  [    0/12672]\n",
      "loss: 1.928675  [ 1600/12672]\n",
      "loss: 2.890795  [ 3200/12672]\n",
      "loss: 3.076265  [ 4800/12672]\n",
      "loss: 1.564316  [ 6400/12672]\n",
      "loss: 4.658322  [ 8000/12672]\n",
      "loss: 3.717896  [ 9600/12672]\n",
      "loss: 3.194772  [11200/12672]\n",
      "AUC: 0.4392620020429009\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 4.358557  [    0/12672]\n",
      "loss: 2.625195  [ 1600/12672]\n",
      "loss: 1.538989  [ 3200/12672]\n",
      "loss: 1.708174  [ 4800/12672]\n",
      "loss: 2.467145  [ 6400/12672]\n",
      "loss: 3.856286  [ 8000/12672]\n",
      "loss: 2.485886  [ 9600/12672]\n",
      "loss: 1.081167  [11200/12672]\n",
      "AUC: 0.4465653728294177\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.626724  [    0/12672]\n",
      "loss: 1.926644  [ 1600/12672]\n",
      "loss: 2.824393  [ 3200/12672]\n",
      "loss: 2.185645  [ 4800/12672]\n",
      "loss: 1.831344  [ 6400/12672]\n",
      "loss: 5.649817  [ 8000/12672]\n",
      "loss: 1.932839  [ 9600/12672]\n",
      "loss: 3.826272  [11200/12672]\n",
      "AUC: 0.45574565883554646\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.739473  [    0/12672]\n",
      "loss: 0.730412  [ 1600/12672]\n",
      "loss: 0.680586  [ 3200/12672]\n",
      "loss: 0.683407  [ 4800/12672]\n",
      "loss: 0.683093  [ 6400/12672]\n",
      "loss: 0.670515  [ 8000/12672]\n",
      "loss: 0.680596  [ 9600/12672]\n",
      "loss: 0.673580  [11200/12672]\n",
      "AUC: 0.5561159346271706\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.680497  [    0/12672]\n",
      "loss: 0.683900  [ 1600/12672]\n",
      "loss: 0.681862  [ 3200/12672]\n",
      "loss: 0.677299  [ 4800/12672]\n",
      "loss: 0.686357  [ 6400/12672]\n",
      "loss: 0.697472  [ 8000/12672]\n",
      "loss: 0.679971  [ 9600/12672]\n",
      "loss: 0.677025  [11200/12672]\n",
      "AUC: 0.5609295199182839\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.690576  [    0/12672]\n",
      "loss: 0.685525  [ 1600/12672]\n",
      "loss: 0.682388  [ 3200/12672]\n",
      "loss: 0.667714  [ 4800/12672]\n",
      "loss: 0.683412  [ 6400/12672]\n",
      "loss: 0.686263  [ 8000/12672]\n",
      "loss: 0.663379  [ 9600/12672]\n",
      "loss: 0.678121  [11200/12672]\n",
      "AUC: 0.5696246169560777\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.667578  [    0/12672]\n",
      "loss: 0.703735  [ 1600/12672]\n",
      "loss: 0.680035  [ 3200/12672]\n",
      "loss: 0.677198  [ 4800/12672]\n",
      "loss: 0.674167  [ 6400/12672]\n",
      "loss: 0.669263  [ 8000/12672]\n",
      "loss: 0.685612  [ 9600/12672]\n",
      "loss: 0.677715  [11200/12672]\n",
      "AUC: 0.5576225740551584\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.662701  [    0/12672]\n",
      "loss: 0.654063  [ 1600/12672]\n",
      "loss: 0.675571  [ 3200/12672]\n",
      "loss: 0.690289  [ 4800/12672]\n",
      "loss: 0.666266  [ 6400/12672]\n",
      "loss: 0.688185  [ 8000/12672]\n",
      "loss: 0.674111  [ 9600/12672]\n",
      "loss: 0.682021  [11200/12672]\n",
      "AUC: 0.5517492339121552\n",
      "sklearn AUC: 0.5421603677221655\n",
      "##############################\n",
      "SESSION 10\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.747092  [    0/12672]\n",
      "loss: 2.134240  [ 1600/12672]\n",
      "loss: 2.443061  [ 3200/12672]\n",
      "loss: 1.730206  [ 4800/12672]\n",
      "loss: 2.806847  [ 6400/12672]\n",
      "loss: 1.903388  [ 8000/12672]\n",
      "loss: 2.010165  [ 9600/12672]\n",
      "loss: 2.205505  [11200/12672]\n",
      "AUC: 0.48868654553409074\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.857345  [    0/12672]\n",
      "loss: 2.565056  [ 1600/12672]\n",
      "loss: 2.319701  [ 3200/12672]\n",
      "loss: 2.371958  [ 4800/12672]\n",
      "loss: 1.830356  [ 6400/12672]\n",
      "loss: 1.957260  [ 8000/12672]\n",
      "loss: 2.944755  [ 9600/12672]\n",
      "loss: 2.404234  [11200/12672]\n",
      "AUC: 0.464760811014041\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 4.926994  [    0/12672]\n",
      "loss: 1.950847  [ 1600/12672]\n",
      "loss: 1.821035  [ 3200/12672]\n",
      "loss: 2.953534  [ 4800/12672]\n",
      "loss: 2.656129  [ 6400/12672]\n",
      "loss: 1.419718  [ 8000/12672]\n",
      "loss: 4.149124  [ 9600/12672]\n",
      "loss: 2.255082  [11200/12672]\n",
      "AUC: 0.45230575721531796\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.842299  [    0/12672]\n",
      "loss: 3.020386  [ 1600/12672]\n",
      "loss: 2.680107  [ 3200/12672]\n",
      "loss: 2.355110  [ 4800/12672]\n",
      "loss: 2.069086  [ 6400/12672]\n",
      "loss: 2.094866  [ 8000/12672]\n",
      "loss: 2.017154  [ 9600/12672]\n",
      "loss: 2.069103  [11200/12672]\n",
      "AUC: 0.4611514430635877\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.357656  [    0/12672]\n",
      "loss: 2.260125  [ 1600/12672]\n",
      "loss: 1.751516  [ 3200/12672]\n",
      "loss: 2.624945  [ 4800/12672]\n",
      "loss: 4.657305  [ 6400/12672]\n",
      "loss: 1.384911  [ 8000/12672]\n",
      "loss: 1.991749  [ 9600/12672]\n",
      "loss: 1.801338  [11200/12672]\n",
      "AUC: 0.4585332841146794\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 3.550550  [    0/12672]\n",
      "loss: 0.734040  [ 1600/12672]\n",
      "loss: 0.671116  [ 3200/12672]\n",
      "loss: 0.682967  [ 4800/12672]\n",
      "loss: 0.672268  [ 6400/12672]\n",
      "loss: 0.678532  [ 8000/12672]\n",
      "loss: 0.673705  [ 9600/12672]\n",
      "loss: 0.680717  [11200/12672]\n",
      "AUC: 0.5988953146575886\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.679924  [    0/12672]\n",
      "loss: 0.683611  [ 1600/12672]\n",
      "loss: 0.678849  [ 3200/12672]\n",
      "loss: 0.681704  [ 4800/12672]\n",
      "loss: 0.688862  [ 6400/12672]\n",
      "loss: 0.678283  [ 8000/12672]\n",
      "loss: 0.690421  [ 9600/12672]\n",
      "loss: 0.687956  [11200/12672]\n",
      "AUC: 0.5816414421065583\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.690609  [    0/12672]\n",
      "loss: 0.692962  [ 1600/12672]\n",
      "loss: 0.684245  [ 3200/12672]\n",
      "loss: 0.685172  [ 4800/12672]\n",
      "loss: 0.665831  [ 6400/12672]\n",
      "loss: 0.691624  [ 8000/12672]\n",
      "loss: 0.692538  [ 9600/12672]\n",
      "loss: 0.682412  [11200/12672]\n",
      "AUC: 0.574832861654567\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.680462  [    0/12672]\n",
      "loss: 0.689853  [ 1600/12672]\n",
      "loss: 0.698322  [ 3200/12672]\n",
      "loss: 0.702228  [ 4800/12672]\n",
      "loss: 0.675039  [ 6400/12672]\n",
      "loss: 0.674736  [ 8000/12672]\n",
      "loss: 0.692106  [ 9600/12672]\n",
      "loss: 0.680961  [11200/12672]\n",
      "AUC: 0.5889832246421394\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.695569  [    0/12672]\n",
      "loss: 0.660752  [ 1600/12672]\n",
      "loss: 0.682156  [ 3200/12672]\n",
      "loss: 0.675261  [ 4800/12672]\n",
      "loss: 0.678380  [ 6400/12672]\n",
      "loss: 0.681897  [ 8000/12672]\n",
      "loss: 0.672772  [ 9600/12672]\n",
      "loss: 0.682676  [11200/12672]\n",
      "AUC: 0.5868094007628891\n",
      "sklearn AUC: 0.5894617393325404\n",
      "##############################\n",
      "SESSION 11\n",
      "##############################\n",
      "------------------------------\n",
      "Epoch 1\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.762599  [    0/12672]\n",
      "loss: 3.109327  [ 1600/12672]\n",
      "loss: 2.203877  [ 3200/12672]\n",
      "loss: 2.072303  [ 4800/12672]\n",
      "loss: 3.624678  [ 6400/12672]\n",
      "loss: 3.923590  [ 8000/12672]\n",
      "loss: 1.967873  [ 9600/12672]\n",
      "loss: 3.514510  [11200/12672]\n",
      "AUC: 0.5344982078853047\n",
      "------------------------------\n",
      "Epoch 2\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.102321  [    0/12672]\n",
      "loss: 1.907258  [ 1600/12672]\n",
      "loss: 1.556818  [ 3200/12672]\n",
      "loss: 2.280433  [ 4800/12672]\n",
      "loss: 2.334133  [ 6400/12672]\n",
      "loss: 3.210814  [ 8000/12672]\n",
      "loss: 3.180779  [ 9600/12672]\n",
      "loss: 2.865125  [11200/12672]\n",
      "AUC: 0.5500672043010754\n",
      "------------------------------\n",
      "Epoch 3\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.912372  [    0/12672]\n",
      "loss: 1.780535  [ 1600/12672]\n",
      "loss: 1.779524  [ 3200/12672]\n",
      "loss: 2.340295  [ 4800/12672]\n",
      "loss: 2.340515  [ 6400/12672]\n",
      "loss: 2.004230  [ 8000/12672]\n",
      "loss: 2.034508  [ 9600/12672]\n",
      "loss: 2.752493  [11200/12672]\n",
      "AUC: 0.5422860004216741\n",
      "------------------------------\n",
      "Epoch 4\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 1.625462  [    0/12672]\n",
      "loss: 3.492640  [ 1600/12672]\n",
      "loss: 1.486504  [ 3200/12672]\n",
      "loss: 1.835562  [ 4800/12672]\n",
      "loss: 3.050161  [ 6400/12672]\n",
      "loss: 2.866147  [ 8000/12672]\n",
      "loss: 2.145503  [ 9600/12672]\n",
      "loss: 2.096657  [11200/12672]\n",
      "AUC: 0.5515101201771031\n",
      "------------------------------\n",
      "Epoch 5\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.030783  [    0/12672]\n",
      "loss: 3.332538  [ 1600/12672]\n",
      "loss: 4.459032  [ 3200/12672]\n",
      "loss: 2.288139  [ 4800/12672]\n",
      "loss: 2.425411  [ 6400/12672]\n",
      "loss: 1.900237  [ 8000/12672]\n",
      "loss: 1.952973  [ 9600/12672]\n",
      "loss: 1.955346  [11200/12672]\n",
      "AUC: 0.5284695867594349\n",
      "------------------------------\n",
      "Epoch 6\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 2.256819  [    0/12672]\n",
      "loss: 0.703625  [ 1600/12672]\n",
      "loss: 0.693433  [ 3200/12672]\n",
      "loss: 0.671510  [ 4800/12672]\n",
      "loss: 0.687053  [ 6400/12672]\n",
      "loss: 0.670038  [ 8000/12672]\n",
      "loss: 0.682926  [ 9600/12672]\n",
      "loss: 0.681993  [11200/12672]\n",
      "AUC: 0.5704590976175417\n",
      "------------------------------\n",
      "Epoch 7\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.667290  [    0/12672]\n",
      "loss: 0.686338  [ 1600/12672]\n",
      "loss: 0.675053  [ 3200/12672]\n",
      "loss: 0.679569  [ 4800/12672]\n",
      "loss: 0.676187  [ 6400/12672]\n",
      "loss: 0.680209  [ 8000/12672]\n",
      "loss: 0.693559  [ 9600/12672]\n",
      "loss: 0.687559  [11200/12672]\n",
      "AUC: 0.567652329749104\n",
      "------------------------------\n",
      "Epoch 8\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.681580  [    0/12672]\n",
      "loss: 0.682389  [ 1600/12672]\n",
      "loss: 0.695546  [ 3200/12672]\n",
      "loss: 0.699278  [ 4800/12672]\n",
      "loss: 0.672103  [ 6400/12672]\n",
      "loss: 0.682924  [ 8000/12672]\n",
      "loss: 0.688692  [ 9600/12672]\n",
      "loss: 0.680273  [11200/12672]\n",
      "AUC: 0.5961285051655072\n",
      "------------------------------\n",
      "Epoch 9\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.667543  [    0/12672]\n",
      "loss: 0.689716  [ 1600/12672]\n",
      "loss: 0.669873  [ 3200/12672]\n",
      "loss: 0.687924  [ 4800/12672]\n",
      "loss: 0.681795  [ 6400/12672]\n",
      "loss: 0.673977  [ 8000/12672]\n",
      "loss: 0.692535  [ 9600/12672]\n",
      "loss: 0.664317  [11200/12672]\n",
      "AUC: 0.5121494834492937\n",
      "------------------------------\n",
      "Epoch 10\n",
      "------------------------------\n",
      "yay training\n",
      "loss: 0.690346  [    0/12672]\n",
      "loss: 0.694836  [ 1600/12672]\n",
      "loss: 0.690349  [ 3200/12672]\n",
      "loss: 0.694001  [ 4800/12672]\n",
      "loss: 0.684490  [ 6400/12672]\n",
      "loss: 0.691564  [ 8000/12672]\n",
      "loss: 0.690221  [ 9600/12672]\n",
      "loss: 0.678353  [11200/12672]\n",
      "AUC: 0.6086469534050181\n"
     ]
    }
   ],
   "source": [
    "set_seed(56)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch_auc_list = []\n",
    "sk_auc_list = []\n",
    "logo = LeaveOneGroupOut()\n",
    "for (i, (train_idx, test_idx)) in tqdm(list(enumerate(logo.split(X, y, groups=sessions)))):\n",
    "    print(f\"{'#'*30}\\nSESSION {i}\\n{'#'*30}\")\n",
    "    ## create model ##\n",
    "    model = LogisticRegressionTorch(X.shape[-1])\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    alpha = 1\n",
    "    lr = 5e-2\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=10)\n",
    "    ## data ##\n",
    "    train_set = SimpleDataset(X[train_idx], y[train_idx])\n",
    "    test_set = SimpleDataset(X[test_idx], y[test_idx])\n",
    "    ## class balancing ##\n",
    "    cls_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(train_set.y.detach().numpy()),\n",
    "        y=train_set.y.detach().numpy(),\n",
    "    )\n",
    "    weights = cls_weights[train_set.y.detach().numpy().astype(int)]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights, len(train_set.y.detach().numpy()), replacement=True\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=200, sampler=sampler)\n",
    "\n",
    "    ## training epochs ##\n",
    "    EPOCHS = 10\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[2, 4, 6, 8])\n",
    "    for t in range(EPOCHS):\n",
    "        print(f\"{'-'*30}\\nEpoch {t+1}\\n{'-'*30}\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, print_nth_batch=8)\n",
    "        out = test_auc_score(test_set, model)\n",
    "        if t in scheduler.milestones:\n",
    "            scheduler.step()\n",
    "    torch_auc_list.append(out)\n",
    "\n",
    "    ## STANDARD SKLEARN LOGISTIC REGRESSION ###\n",
    "    lr_sk = LogisticRegression(\n",
    "        # penalty=\"none\", class_weight=\"balanced\", fit_intercept=True, max_iter=1000\n",
    "        C=1e-4, class_weight=\"balanced\", fit_intercept=True, max_iter=1000, solver='saga'\n",
    "    )\n",
    "    lr_sk.fit(X=X_npy[train_idx], y=y_npy[train_idx])\n",
    "    pred = lr_sk.predict_proba(X_npy[test_idx])[:, 1]\n",
    "    score = roc_auc_score(y_true=y_npy[test_idx], y_score=pred)\n",
    "    sk_auc_list.append(score)\n",
    "    print(\"sklearn AUC:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e563377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data={\"sklearn\":sk_auc_list, \"pytorch\":torch_auc_list})\n",
    "df = pd.DataFrame(data={\"pytorch\":torch_auc_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e73a8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"LTP093_loso_sgd_l2_unit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7005d1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29208d330>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['sklearn'], bins=10, label='sklearn', alpha=.5)\n",
    "plt.hist(df['pytorch'], bins=10, label='pytorch', alpha=.5)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (3.10)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
